{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-21T11:42:52.972452Z","iopub.execute_input":"2023-06-21T11:42:52.972877Z","iopub.status.idle":"2023-06-21T11:42:52.980058Z","shell.execute_reply.started":"2023-06-21T11:42:52.972833Z","shell.execute_reply":"2023-06-21T11:42:52.978988Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport random\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport seaborn as sb\nimport torch \nfrom torchvision import models\nfrom torch import nn\nfrom torch import optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.models.vision_transformer import vit_b_16\nfrom torchvision.utils import make_grid\nfrom torch.autograd import Variable\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score, accuracy_score, precision_recall_fscore_support\nimport shutil\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#os.mkdir(\"/kaggle/working/code\")\n#os.mkdir(\"/kaggle/working/model\")\n#os.mkdir(\"/kaggle/working/output\")\nshutil.copyfile(src=\"/kaggle/input/modelos/convnext.py\", \n                dst=\"/kaggle/working/code/convnext.py\")\nshutil.copyfile(src=\"/kaggle/input/modelos/convnext_tiny_1k_224_ema.pth\", \n                dst=\"/kaggle/working/model/convnext_tiny_1k_224_ema.pth\")\nshutil.copyfile(src=\"/kaggle/input/modelos/vit_b_16-c867db91.pth\", \n                dst=\"/kaggle/working/model/vit_b_16-c867db91.pth\")\n\nos.chdir(\"/kaggle/working/code\")\n\n\nfrom convnext import ConvNeXt\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T12:24:20.283150Z","iopub.execute_input":"2023-06-21T12:24:20.283579Z","iopub.status.idle":"2023-06-21T12:24:26.500584Z","shell.execute_reply.started":"2023-06-21T12:24:20.283544Z","shell.execute_reply":"2023-06-21T12:24:26.499524Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"local_arquivos='/kaggle/input/140k-real-and-fake-faces'\ntreino = pd.read_csv(local_arquivos + \"/train.csv\")\nteste = pd.read_csv(local_arquivos + \"/test.csv\")\nprint(teste.shape)\nprint(treino.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T12:25:39.569027Z","iopub.execute_input":"2023-06-21T12:25:39.569385Z","iopub.status.idle":"2023-06-21T12:25:39.883879Z","shell.execute_reply.started":"2023-06-21T12:25:39.569357Z","shell.execute_reply":"2023-06-21T12:25:39.882752Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"(20000, 6)\n(100000, 6)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Instanciando o modelo ConvNeXt \ndef ConvNeXt_model():\n    model_conv=ConvNeXt()\n    state_dict = torch.load('/kaggle/working/model/convnext_tiny_1k_224_ema.pth')\n    model_conv.load_state_dict(state_dict[\"model\"])\n    \n    return model_conv\n\ndef ViT_model():\n    model_vit=vit_b_16(pretrained=True)\n    \n    return model_vit\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T12:31:33.020571Z","iopub.execute_input":"2023-06-21T12:31:33.020995Z","iopub.status.idle":"2023-06-21T12:31:33.026732Z","shell.execute_reply.started":"2023-06-21T12:31:33.020936Z","shell.execute_reply":"2023-06-21T12:31:33.025851Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"model=ConvNeXt_model()\nmodel.head=torch.nn.Linear(model.head.in_features, 2)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T11:42:54.030872Z","iopub.execute_input":"2023-06-21T11:42:54.031224Z","iopub.status.idle":"2023-06-21T11:42:54.671326Z","shell.execute_reply.started":"2023-06-21T11:42:54.031193Z","shell.execute_reply":"2023-06-21T11:42:54.670287Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-06-21T11:42:54.672650Z","iopub.execute_input":"2023-06-21T11:42:54.673313Z","iopub.status.idle":"2023-06-21T11:42:54.678210Z","shell.execute_reply.started":"2023-06-21T11:42:54.673276Z","shell.execute_reply":"2023-06-21T11:42:54.677293Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.AdamW(model_conv.parameters(), lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T11:42:54.679484Z","iopub.execute_input":"2023-06-21T11:42:54.680466Z","iopub.status.idle":"2023-06-21T11:42:54.691595Z","shell.execute_reply.started":"2023-06-21T11:42:54.680430Z","shell.execute_reply":"2023-06-21T11:42:54.690641Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n    \ncriterion = nn.CrossEntropyLoss()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T11:42:54.696115Z","iopub.execute_input":"2023-06-21T11:42:54.696597Z","iopub.status.idle":"2023-06-21T11:42:54.708088Z","shell.execute_reply.started":"2023-06-21T11:42:54.696564Z","shell.execute_reply":"2023-06-21T11:42:54.707110Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-06-21T11:42:54.709447Z","iopub.execute_input":"2023-06-21T11:42:54.709931Z","iopub.status.idle":"2023-06-21T11:42:54.715587Z","shell.execute_reply.started":"2023-06-21T11:42:54.709900Z","shell.execute_reply":"2023-06-21T11:42:54.714509Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"train_acc, teste_acc, train_loss, teste_loss = [], [], [], []\ntrain_precision, teste_precision, train_recall, teste_recall = [], [], [], []\ntrain_f1, teste_f1 = [], []\ndf = pd.DataFrame(columns=['Modelo','Experimento','Epoch', 'Train ACC', 'Train Loss', 'Train F1', 'Test ACC', 'Test Loss', 'Test F1'])","metadata":{"execution":{"iopub.status.busy":"2023-06-21T12:48:21.543619Z","iopub.execute_input":"2023-06-21T12:48:21.544170Z","iopub.status.idle":"2023-06-21T12:48:21.553566Z","shell.execute_reply.started":"2023-06-21T12:48:21.544132Z","shell.execute_reply":"2023-06-21T12:48:21.552742Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\n\ndef plot_experiment_graphs(df, experiment_number):\n    experiment_df = df[df['Experimento'] == experiment_number]\n\n    # Plot epoch x train F1\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Train F1'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Train F1')\n    plt.title(f'Experimento {experiment_number} - Train F1')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x train accuracy\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Train ACC'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Acurácia de Treino')\n    plt.title(f'Experimento {experiment_number} - Acurácia de Treino')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x train loss\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Train Loss'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Perda de Treino')\n    plt.title(f'Experimento {experiment_number} - Perda de Treino')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x test F1\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Test F1'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Test F1')\n    plt.title(f'Experimento {experiment_number} - Test F1')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x test accuracy\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Test ACC'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Acurácia de Teste')\n    plt.title(f'Experimento {experiment_number} - Acurácia de Teste')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x test loss\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Test Loss'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Perda de Teste')\n    plt.title(f'Experimento {experiment_number} - Perda de Teste')\n    plt.tight_layout()\n    plt.show()\n\ndef plot_general_graphs(df):\n    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n\n    # Plot epoch x train F1\n    ax1 = axes[0, 0]\n    for experiment_number in df['Experimento'].unique():\n        experiment_df = df[df['Experimento'] == experiment_number]\n        ax1.plot(experiment_df['Epoch'], experiment_df['Train F1'], marker='o', label=f'Experimento {experiment_number}')\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Train F1')\n    ax1.set_title('Geral - Train F1')\n    ax1.legend()\n\n    # Plot epoch x train loss\n    ax2 = axes[0, 1]\n    for experiment_number in df['Experimento'].unique():\n        experiment_df = df[df['Experimento'] == experiment_number]\n        ax2.plot(experiment_df['Epoch'], experiment_df['Train Loss'], marker='o', label=f'Experimento {experiment_number}')\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Perda de Treino')\n    ax2.set_title('Geral - Perda de Treino')\n    ax2.legend()\n\n    # Plot epoch x test F1\n    ax3 = axes[1, 0]\n    for experiment_number in df['Experimento'].unique():\n        experiment_df = df[df['Experimento'] == experiment_number]\n        ax3.plot(experiment_df['Epoch'], experiment_df['Test F1'], marker='o', label=f'Experimento {experiment_number}')\n    ax3.set_xlabel('Epoch')\n    ax3.set_ylabel('Test F1')\n    ax3.set_title('Geral - Test F1')\n    ax3.legend()\n\n    # Plot epoch x test loss\n    ax4 = axes[1, 1]\n    for experiment_number in df['Experimento'].unique():\n        experiment_df = df[df['Experimento'] == experiment_number]\n        ax4.plot(experiment_df['Epoch'], experiment_df['Test Loss'], marker='o', label=f'Experimento {experiment_number}')\n    ax4.set_xlabel('Epoch')\n    ax4.set_ylabel('Perda de Teste')\n    ax4.set_title('Geral - Perda de Teste')\n    ax4.legend()\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T11:42:54.731304Z","iopub.execute_input":"2023-06-21T11:42:54.731714Z","iopub.status.idle":"2023-06-21T11:42:54.753799Z","shell.execute_reply.started":"2023-06-21T11:42:54.731605Z","shell.execute_reply":"2023-06-21T11:42:54.752621Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":" # Função de treino genérica\ndef train(model, dataloader, criterion, optimizer, device, ft, epoch, exp, model_type):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    y_true,y_pred=[], []\n    \n    loop = tqdm(enumerate(dataloader), total=len(dataloader))\n    for batch_idx, (images, labels) in loop:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        if ft==False:\n            for param in model.parameters():\n                param.requires_grad=False\n                \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            optimizer.step()\n            \n            for param in model.parameters():\n                param.requires_grad=True\n        else:    \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n                \n        running_loss += loss.item()\n        predicted = outputs.argmax(dim = 1)\n    \n        y_true.extend(labels.cpu().tolist())\n        y_pred.extend(predicted.cpu().tolist())\n\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n        \n        loop.set_description(f\"[Epoch {(epoch+1)}]\")\n        loop.set_postfix(loss=loss.item())\n        \n    if scheduler:\n        scheduler.step()\n        \n    train_loss = running_loss / len(dataloader.dataset)  \n    accuracy = accuracy_score(y_true, y_pred)\n    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro',zero_division=0)\n\n    print(f\"Train Loss: {train_loss:.6f} | Train Accuracy: {(accuracy * 100):.2f}% | Train F1-Score: {f1:.6f}\")\n    \n    model_name= f'model{model_type}_params_exp{exp}'\n    torch.save(model.state_dict(), os.path.join('/kaggle/working/model', 'model_params.pth'))\n   \n    return train_loss, accuracy, f1","metadata":{"execution":{"iopub.status.busy":"2023-06-21T12:49:24.346242Z","iopub.execute_input":"2023-06-21T12:49:24.346706Z","iopub.status.idle":"2023-06-21T12:49:24.364684Z","shell.execute_reply.started":"2023-06-21T12:49:24.346670Z","shell.execute_reply":"2023-06-21T12:49:24.363659Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"# Função de teste genérica\ndef test(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    y_pred, y_true= [], []\n\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n\n            running_loss += loss.item()\n            predicted = outputs.argmax(dim = 1)\n            \n            y_true.extend(labels.cpu().tolist())\n            y_pred.extend(predicted.cpu().tolist())\n            \n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    test_loss = running_loss / len(list(dataloader.dataset))\n    test_accuracy = accuracy = accuracy_score(y_true, y_pred)\n    precision, recall, test_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro',zero_division=0)\n    \n    print(f\"Test Loss: {test_loss:.6f} | Test Accuracy: {(test_accuracy * 100):.2f}% | Test F1-Score: {test_f1:.6f}\")\n    return test_loss, test_accuracy, test_f1\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T11:42:54.772193Z","iopub.execute_input":"2023-06-21T11:42:54.772915Z","iopub.status.idle":"2023-06-21T11:42:54.787632Z","shell.execute_reply.started":"2023-06-21T11:42:54.772882Z","shell.execute_reply":"2023-06-21T11:42:54.786933Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Função genérica para treinar, testar\ndef train_model(model_type, exp,model, train_dataloader, test_dataloader, criterion, optimizer, device, num_epochs, ft):\n    model=model.to(device)\n    train_losses = []\n    train_accuracies = []\n    test_losses = []\n    test_accuracies = []\n\n    for epoch in range(num_epochs):\n        print('----------------------------------------------------------------------------')\n        train_loss, train_accuracy, train_f1 = train(model, train_dataloader, criterion, optimizer, device, ft, epoch, exp, model_type)\n        test_loss, test_accuracy,test_f1 = test(model, test_dataloader, criterion, device)\n        df.loc[epoch]=[model_type,exp,epoch+1, train_accuracy, train_loss, train_f1, test_accuracy, test_loss, test_f1]\n        train_losses.append(train_loss)\n        train_accuracies.append(train_accuracy)\n        test_losses.append(test_loss)\n        test_accuracies.append(test_accuracy)\n        print('\\n')\n        \n        \n        \n    return train_losses, train_accuracies, test_losses, test_accuracies\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T12:49:38.135690Z","iopub.execute_input":"2023-06-21T12:49:38.136111Z","iopub.status.idle":"2023-06-21T12:49:38.148032Z","shell.execute_reply.started":"2023-06-21T12:49:38.136077Z","shell.execute_reply":"2023-06-21T12:49:38.146877Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"# Transformações de dados\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(256),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\nlocal_arquivos='/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\nfull_train_dataset = ImageFolder(local_arquivos + \"/train\", transform=transform)\nfull_test_dataset = ImageFolder(local_arquivos + \"/test\", transform=transform)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T11:42:54.806254Z","iopub.execute_input":"2023-06-21T11:42:54.806581Z","iopub.status.idle":"2023-06-21T11:44:47.007551Z","shell.execute_reply.started":"2023-06-21T11:42:54.806553Z","shell.execute_reply":"2023-06-21T11:44:47.006310Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def move_dataloader_to_device(dataloader, device):\n    for batch in dataloader:\n        images, labels = batch\n        images = images.to(device)\n        labels = labels.to(device)\n        yield images, labels","metadata":{"execution":{"iopub.status.busy":"2023-06-21T11:44:47.009195Z","iopub.execute_input":"2023-06-21T11:44:47.009561Z","iopub.status.idle":"2023-06-21T11:44:47.018813Z","shell.execute_reply.started":"2023-06-21T11:44:47.009511Z","shell.execute_reply":"2023-06-21T11:44:47.015458Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"#**Aplicando o protocolo experimental para os seguintes cenários:\n\n#Aumentos de dados: AutoAugment, RandAugment e Mixup\n\n#Fine Tuning: Com e sem\n\n#1 - Sem Fine Tuning\n\n#2 - Com Fine Tuning\n\n#3 - Sem Fine Tuning e com AutoAugment\n\n#4 - Com Fine Tuning e com AutoAugment\n\n#5 - Sem Fine Tuning e com RandAugment\n\n#6 - Com Fine Tuning e com RandAugment\n\n#7 - Sem Fine Tuning e com Mixup\n\n#8 - Com Fine Tuning e com Mixup\n\n#9 - Sem Fine Tuning e com AutoAugment e RandAugment\n\n#10 - Com Fine Tuning e com AutoAugment e RandAugment\n\n#11 - Sem Fine Tuning e com AutoAugment e Mixup\n\n#12 - Com Fine Tuning e com AutoAugment e Mixup\n\n#13 - Sem Fine Tuning e com RandAugment e Mixup\n\n#14 - Com Fine Tuning e com RandAugment e Mixup\n\n#15 - Sem Fine Tuning e com AutoAugment, RandAugment e Mixup\n\n#16 - Com Fine Tuning e com AutoAugment, RandAugment e Mixup\n","metadata":{}},{"cell_type":"code","source":"def run_scenario(model_type, scenario, data_fraction, num_epochs=10, batch_size=32, learning_rate=0.001):\n    num_classes = 2  \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Determinar o número de objetos a serem selecionados\n    num_train_data = int(len(full_train_dataset) * data_fraction)\n    num_test_data = int(len(full_test_dataset) * data_fraction)\n    \n    print(f'Número de objetos de treino: {num_train_data}')\n    print(f'Número de objetos de teste: {num_test_data}')\n\n    # Selecionar aleatoriamente os objetos para os conjuntos de dados\n    train_indices = random.sample(range(len(full_train_dataset)), num_train_data)\n    test_indices = random.sample(range(len(full_test_dataset)), num_test_data)\n\n    # Criar os datasets com a seleção aleatória de objetos\n    train_dataset = torch.utils.data.Subset(full_train_dataset, train_indices)\n    test_dataset = torch.utils.data.Subset(full_test_dataset, test_indices)\n    \n    # Criação dos dataloaders\n    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    test_dataloader = DataLoader(test_dataset, batch_size=int(batch_size/2), shuffle=False)\n    \n    print(\"========================================================================\")\n    \n    if scenario == 1:\n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n        elif model_type == 'vit':\n            model = ViT_model()\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        \n        if model_type == 'convnext':\n            print(\"Experimento 1 - ConvNeXt (Sem Fine-Tuning)\")\n        elif model_type == 'vit':\n            print(\"Experimento 1 - ViT (Sem Fine-Tuning)\")\n        \n        train_losses, train_accuracies, test_losses, test_accuracies = train_model(model_type,1, model, train_dataloader, test_dataloader,\n                                                                                    criterion, optimizer, device, 1, False)\n    elif scenario == 2:\n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n        elif model_type == 'vit':\n            model = ViT_model()\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        \n        if model_type == 'convnext':\n             print(\"Experimento 2 - ConvNeXt (Com Fine-Tuning)\")\n        elif model_type == 'vit':\n            print(\"Experimento 2 - ViT (Com Fine-Tuning)\")\n        \n        train_losses, train_accuracies, test_losses, test_accuracies = train_model(model_type,2, model, train_dataloader, test_dataloader,\n                                                                                    criterion, optimizer, device, num_epochs, True)\n    elif scenario == 3:\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.AutoAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n        \n        augmented_train_dataset = ImageFolder(local_arquivos + \"/train\", transform=augmentation_transforms)\n        augmented_train_dataset = torch.utils.data.Subset(augmented_train_dataset, train_indices)\n        augmented_train_dataloader = DataLoader(augmented_train_dataset, batch_size=batch_size, shuffle=True)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n        elif model_type == 'vit':\n            model = ViT_model()\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        \n        if model_type == 'convnext':\n            print(\"Experimento 3 - ConvNeXt (Sem Fine-Tuning e com AutoAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 3 - ViT (Sem Fine-Tuning e com AutoAugment)\")\n        \n        \n        train_losses, train_accuracies, test_losses, test_accuracies = train_model(model_type,3, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, device, 1, False)\n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n        elif model_type == 'vit':\n            model = ViT_model()\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        \n        if model_type == 'convnext':\n            print(\"Experimento 4 - ConvNeXt (Com Fine-Tuning e com AutoAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 4 - ViT (Com Fine-Tuning e com AutoAugment)\")\n        \n        train_losses, train_accuracies, test_losses, test_accuracies = train_model(model_type,4, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, device, num_epochs, True)\n    \n    elif scenario == 4:\n        augmentation_transforms = transforms.Compose([\n            transforms.RandAugment(),\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\n        augmented_train_dataset = ImageFolder(local_arquivos + \"/train\", transform=augmentation_transforms)\n        augmented_train_dataset = torch.utils.data.Subset(augmented_train_dataset, train_indices)\n        augmented_train_dataloader = DataLoader(augmented_train_dataset, batch_size=batch_size, shuffle=True)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n        elif model_type == 'vit':\n            model = ViT_model()\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n            \n        if model_type == 'convnext':\n            print(\"Experimento 5 - ConvNeXt (Sem Fine-Tuning e com RandAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 5 - ViT (Sem Fine-Tuning e com RandAugment)\")    \n        \n        train_losses, train_accuracies, test_losses, test_accuracies = train_model(model_type,5, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, device, 1, False)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n        elif model_type == 'vit':\n            model = ViT_model()\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        \n        if model_type == 'convnext':\n            print(\"Experimento 6 - ConvNeXt (Com Fine-Tuning e com RandAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 6 - ViT (Com Fine-Tuning e com RandAugment)\")\n        \n        \n        train_losses, train_accuracies, test_losses, test_accuracies = train_model(model_type,6, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, device, num_epochs, True) \n\n    elif scenario == 5:\n        augmentation_transforms = transforms.Compose([\n            transforms.RandAugment(),\n            transforms.AutoAugment(),\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\n        augmented_train_dataset = ImageFolder(local_arquivos + \"/train\", transform=augmentation_transforms)\n        augmented_train_dataset = torch.utils.data.Subset(augmented_train_dataset, train_indices)\n        augmented_train_dataloader = DataLoader(augmented_train_dataset, batch_size=batch_size, shuffle=True)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n        elif model_type == 'vit':\n            model = ViT_model()\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        \n        if model_type == 'convnext':\n            print(\"Experimento 7 - ConvNeXt (Sem Fine-Tuning e com RandAugment e AutoAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 7 - ViT (Sem Fine-Tuning e com RandAugment e AutoAugment)\")\n            \n        train_losses, train_accuracies, test_losses, test_accuracies = train_model(model_type,7, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, device, 1, False)\n      \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n        elif model_type == 'vit':\n            model = ViT_model()\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        \n        if model_type == 'convnext':\n            print(\"Experimento 7 - ConvNeXt (Com Fine-Tuning e com RandAugment e AutoAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 7 - ViT (Com Fine-Tuning e com RandAugment e AutoAugment)\")\n\n        train_losses, train_accuracies, test_losses, test_accuracies = train_model(model_type,8, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, device, num_epochs, True)\n    else:\n        raise ValueError(\"O parâmetro 'scenario' deve ser um número entre 1 e 5.\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T12:55:16.475864Z","iopub.execute_input":"2023-06-21T12:55:16.476349Z","iopub.status.idle":"2023-06-21T12:55:16.520102Z","shell.execute_reply.started":"2023-06-21T12:55:16.476315Z","shell.execute_reply":"2023-06-21T12:55:16.519108Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"run_scenario('convnext',1,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T12:55:20.930923Z","iopub.execute_input":"2023-06-21T12:55:20.931367Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Número de objetos de treino: 10000\nNúmero de objetos de teste: 2000\n========================================================================\nExperimento 1 - ConvNeXt (Sem Fine-Tuning)\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 1]:  88%|████████▊ | 551/625 [01:59<00:16,  4.60it/s, loss=0.62] ","output_type":"stream"}]},{"cell_type":"code","source":"run_scenario('convnext',2,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T12:01:54.809292Z","iopub.execute_input":"2023-06-21T12:01:54.810131Z","iopub.status.idle":"2023-06-21T12:18:44.826173Z","shell.execute_reply.started":"2023-06-21T12:01:54.810091Z","shell.execute_reply":"2023-06-21T12:18:44.824665Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Número de objetos de treino: 10000\nNúmero de objetos de teste: 2000\n========================================================================\nExperimento 2 - ConvNeXt (Com Fine-Tuning)\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 1]: 100%|██████████| 625/625 [04:23<00:00,  2.37it/s, loss=0.0114]  \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.007201 | Train Accuracy: 95.22% | Train F1-Score: 0.952184\nTest Loss: 0.000704 | Test Accuracy: 99.80% | Test F1-Score: 0.997998\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 2]: 100%|██████████| 625/625 [03:32<00:00,  2.94it/s, loss=0.000334]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.001151 | Train Accuracy: 99.37% | Train F1-Score: 0.993698\nTest Loss: 0.000434 | Test Accuracy: 99.85% | Test F1-Score: 0.998498\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 3]: 100%|██████████| 625/625 [03:31<00:00,  2.95it/s, loss=5.59e-5] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000016 | Train Accuracy: 100.00% | Train F1-Score: 1.000000\nTest Loss: 0.000553 | Test Accuracy: 99.90% | Test F1-Score: 0.998999\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 4]: 100%|██████████| 625/625 [03:32<00:00,  2.95it/s, loss=4.17e-5] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000004 | Train Accuracy: 100.00% | Train F1-Score: 1.000000\nTest Loss: 0.000557 | Test Accuracy: 99.90% | Test F1-Score: 0.998999\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 5]:   2%|▏         | 12/625 [00:04<03:44,  2.73it/s, loss=3.95e-5]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_scenario\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[51], line 51\u001b[0m, in \u001b[0;36mrun_scenario\u001b[0;34m(scenario, data_fraction, num_epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m========================================================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExperimento 2 - ConvNeXt (Com Fine-Tuning)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m     train_losses, train_accuracies, test_losses, test_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m                                                                               \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m scenario \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m     55\u001b[0m     augmentation_transforms \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     56\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mResize(\u001b[38;5;241m256\u001b[39m),\n\u001b[1;32m     57\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mCenterCrop(\u001b[38;5;241m256\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \n\u001b[1;32m     62\u001b[0m     ])\n","Cell \u001b[0;32mIn[40], line 11\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(exp, model, train_dataloader, test_dataloader, criterion, optimizer, device, num_epochs, ft)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     train_loss, train_accuracy, train_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     test_loss, test_accuracy,test_f1 \u001b[38;5;241m=\u001b[39m test(model, test_dataloader, criterion, device)\n\u001b[1;32m     13\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[epoch]\u001b[38;5;241m=\u001b[39m[exp,epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, train_accuracy, train_loss, train_f1, test_accuracy, test_loss, test_f1]\n","Cell \u001b[0;32mIn[38], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, criterion, optimizer, device, ft, epoch, exp)\u001b[0m\n\u001b[1;32m     27\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     28\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 30\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39margmax(dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     33\u001b[0m y_true\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist())\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"run_scenario('convnext',3,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T12:18:44.827383Z","iopub.status.idle":"2023-06-21T12:18:44.828468Z","shell.execute_reply.started":"2023-06-21T12:18:44.828197Z","shell.execute_reply":"2023-06-21T12:18:44.828223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('convnext',4,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('convnext',5,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T12:18:44.829659Z","iopub.status.idle":"2023-06-21T12:18:44.834642Z","shell.execute_reply.started":"2023-06-21T12:18:44.834380Z","shell.execute_reply":"2023-06-21T12:18:44.834411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',1,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',2,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',3,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',4,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',5,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}