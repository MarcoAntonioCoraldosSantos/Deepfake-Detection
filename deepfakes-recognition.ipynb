{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-21T14:36:50.705626Z","iopub.execute_input":"2023-06-21T14:36:50.706043Z","iopub.status.idle":"2023-06-21T14:36:50.712303Z","shell.execute_reply.started":"2023-06-21T14:36:50.706011Z","shell.execute_reply":"2023-06-21T14:36:50.710950Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport random\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport seaborn as sb\nimport torch \nfrom torchvision import models\nfrom torch import nn\nfrom torch import optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.models.vision_transformer import vit_b_16, ViT_B_16_Weights\nfrom torchvision.utils import make_grid\nfrom torch.autograd import Variable\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score, accuracy_score, precision_recall_fscore_support\nimport shutil\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ncode_dir = \"/kaggle/working/code\"\nmodel_dir = \"/kaggle/working/model\"\noutput_dir = \"/kaggle/working/output\"\n\nif not os.path.exists(code_dir):\n    os.mkdir(code_dir)\n\nif not os.path.exists(model_dir):\n    os.mkdir(model_dir)\n\nif not os.path.exists(output_dir):\n    os.mkdir(output_dir)\n    \nshutil.copyfile(src=\"/kaggle/input/modelos/convnext.py\", \n                dst=\"/kaggle/working/code/convnext.py\")\nshutil.copyfile(src=\"/kaggle/input/modelos/convnext_tiny_1k_224_ema.pth\", \n                dst=\"/kaggle/working/model/convnext_tiny_1k_224_ema.pth\")\nshutil.copyfile(src=\"/kaggle/input/modelos/vit_b_16-c867db91.pth\", \n                dst=\"/kaggle/working/model/vit_b_16-c867db91.pth\")\n\nos.chdir(\"/kaggle/working/code\")\n\n\nfrom convnext import ConvNeXt\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:36:50.725929Z","iopub.execute_input":"2023-06-21T14:36:50.727115Z","iopub.status.idle":"2023-06-21T14:36:51.400435Z","shell.execute_reply.started":"2023-06-21T14:36:50.727079Z","shell.execute_reply":"2023-06-21T14:36:51.398956Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"local_arquivos='/kaggle/input/140k-real-and-fake-faces'\ntreino = pd.read_csv(local_arquivos + \"/train.csv\")\nteste = pd.read_csv(local_arquivos + \"/test.csv\")\nprint(teste.shape)\nprint(treino.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:36:51.402444Z","iopub.execute_input":"2023-06-21T14:36:51.403040Z","iopub.status.idle":"2023-06-21T14:36:51.725602Z","shell.execute_reply.started":"2023-06-21T14:36:51.403002Z","shell.execute_reply":"2023-06-21T14:36:51.724545Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"(20000, 6)\n(100000, 6)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Instanciando o modelo ConvNeXt \ndef ConvNeXt_model():\n    model_conv=ConvNeXt()\n    state_dict = torch.load('/kaggle/working/model/convnext_tiny_1k_224_ema.pth')\n    model_conv.load_state_dict(state_dict[\"model\"])\n    \n    return model_conv\n\ndef ViT_model():\n    model_vit=vit_b_16(pretrained=True)\n    return model_vit\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:36:51.727756Z","iopub.execute_input":"2023-06-21T14:36:51.728759Z","iopub.status.idle":"2023-06-21T14:36:51.734827Z","shell.execute_reply.started":"2023-06-21T14:36:51.728722Z","shell.execute_reply":"2023-06-21T14:36:51.733724Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:36:51.738078Z","iopub.execute_input":"2023-06-21T14:36:51.738477Z","iopub.status.idle":"2023-06-21T14:36:51.747156Z","shell.execute_reply.started":"2023-06-21T14:36:51.738443Z","shell.execute_reply":"2023-06-21T14:36:51.746118Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"  criterion = nn.CrossEntropyLoss()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:36:51.750657Z","iopub.execute_input":"2023-06-21T14:36:51.750988Z","iopub.status.idle":"2023-06-21T14:36:51.761260Z","shell.execute_reply.started":"2023-06-21T14:36:51.750954Z","shell.execute_reply":"2023-06-21T14:36:51.760262Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:36:51.762764Z","iopub.execute_input":"2023-06-21T14:36:51.763579Z","iopub.status.idle":"2023-06-21T14:36:51.774179Z","shell.execute_reply.started":"2023-06-21T14:36:51.763545Z","shell.execute_reply":"2023-06-21T14:36:51.773098Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"train_acc, teste_acc, train_loss, teste_loss = [], [], [], []\ntrain_precision, teste_precision, train_recall, teste_recall = [], [], [], []\ntrain_f1, teste_f1 = [], []\ndf = pd.DataFrame(columns=['Modelo','Experimento','Epoch', 'Train ACC', 'Train Loss', 'Train F1', 'Test ACC', 'Test Loss', 'Test F1'])","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:36:51.776723Z","iopub.execute_input":"2023-06-21T14:36:51.777016Z","iopub.status.idle":"2023-06-21T14:36:51.787014Z","shell.execute_reply.started":"2023-06-21T14:36:51.776991Z","shell.execute_reply":"2023-06-21T14:36:51.786078Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\n\ndef plot_experiment_graphs(df, experiment_number):\n    experiment_df = df[df['Experimento'] == experiment_number]\n\n    # Plot epoch x train F1\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Train F1'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Train F1')\n    plt.title(f'Experimento {experiment_number} - Train F1')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x train accuracy\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Train ACC'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Acurácia de Treino')\n    plt.title(f'Experimento {experiment_number} - Acurácia de Treino')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x train loss\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Train Loss'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Perda de Treino')\n    plt.title(f'Experimento {experiment_number} - Perda de Treino')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x test F1\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Test F1'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Test F1')\n    plt.title(f'Experimento {experiment_number} - Test F1')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x test accuracy\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Test ACC'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Acurácia de Teste')\n    plt.title(f'Experimento {experiment_number} - Acurácia de Teste')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x test loss\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Test Loss'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Perda de Teste')\n    plt.title(f'Experimento {experiment_number} - Perda de Teste')\n    plt.tight_layout()\n    plt.show()\n\ndef plot_general_graphs(df):\n    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n\n    # Plot epoch x train F1\n    ax1 = axes[0, 0]\n    for experiment_number in df['Experimento'].unique():\n        experiment_df = df[df['Experimento'] == experiment_number]\n        ax1.plot(experiment_df['Epoch'], experiment_df['Train F1'], marker='o', label=f'Experimento {experiment_number}')\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Train F1')\n    ax1.set_title('Geral - Train F1')\n    ax1.legend()\n\n    # Plot epoch x train loss\n    ax2 = axes[0, 1]\n    for experiment_number in df['Experimento'].unique():\n        experiment_df = df[df['Experimento'] == experiment_number]\n        ax2.plot(experiment_df['Epoch'], experiment_df['Train Loss'], marker='o', label=f'Experimento {experiment_number}')\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Perda de Treino')\n    ax2.set_title('Geral - Perda de Treino')\n    ax2.legend()\n\n    # Plot epoch x test F1\n    ax3 = axes[1, 0]\n    for experiment_number in df['Experimento'].unique():\n        experiment_df = df[df['Experimento'] == experiment_number]\n        ax3.plot(experiment_df['Epoch'], experiment_df['Test F1'], marker='o', label=f'Experimento {experiment_number}')\n    ax3.set_xlabel('Epoch')\n    ax3.set_ylabel('Test F1')\n    ax3.set_title('Geral - Test F1')\n    ax3.legend()\n\n    # Plot epoch x test loss\n    ax4 = axes[1, 1]\n    for experiment_number in df['Experimento'].unique():\n        experiment_df = df[df['Experimento'] == experiment_number]\n        ax4.plot(experiment_df['Epoch'], experiment_df['Test Loss'], marker='o', label=f'Experimento {experiment_number}')\n    ax4.set_xlabel('Epoch')\n    ax4.set_ylabel('Perda de Teste')\n    ax4.set_title('Geral - Perda de Teste')\n    ax4.legend()\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:36:51.788577Z","iopub.execute_input":"2023-06-21T14:36:51.789243Z","iopub.status.idle":"2023-06-21T14:36:51.811169Z","shell.execute_reply.started":"2023-06-21T14:36:51.789213Z","shell.execute_reply":"2023-06-21T14:36:51.810016Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":" # Função de treino genérica\ndef train(model, dataloader, criterion, optimizer, scheduler, device, ft, epoch, exp, model_type):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    y_true,y_pred=[], []\n    \n    loop = tqdm(enumerate(dataloader), total=len(dataloader))\n    for batch_idx, (images, labels) in loop:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        if ft==False:\n            for param in model.parameters():\n                param.requires_grad=False\n                \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            optimizer.step()\n            \n            for param in model.parameters():\n                param.requires_grad=True\n        else:    \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n                \n        running_loss += loss.item()\n        predicted = outputs.argmax(dim = 1)\n    \n        y_true.extend(labels.cpu().tolist())\n        y_pred.extend(predicted.cpu().tolist())\n\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n        \n        loop.set_description(f\"[Epoch {(epoch+1)}]\")\n        loop.set_postfix(loss=loss.item())\n        \n    if scheduler:\n        scheduler.step()\n        \n    train_loss = running_loss / len(dataloader.dataset)  \n    accuracy = accuracy_score(y_true, y_pred)\n    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro',zero_division=0)\n\n    print(f\"Train Loss: {train_loss:.6f} | Train Accuracy: {(accuracy * 100):.2f}% | Train F1-Score: {f1:.6f}\")\n    \n    model_name= f'model{model_type}_params_exp{exp}'\n    torch.save(model.state_dict(), os.path.join('/kaggle/working/model', 'model_params.pth'))\n   \n    return train_loss, accuracy, f1","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:36:51.814420Z","iopub.execute_input":"2023-06-21T14:36:51.814735Z","iopub.status.idle":"2023-06-21T14:36:51.829899Z","shell.execute_reply.started":"2023-06-21T14:36:51.814709Z","shell.execute_reply":"2023-06-21T14:36:51.828929Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"# Função de teste genérica\ndef test(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    y_pred, y_true= [], []\n\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n\n            running_loss += loss.item()\n            predicted = outputs.argmax(dim = 1)\n            \n            y_true.extend(labels.cpu().tolist())\n            y_pred.extend(predicted.cpu().tolist())\n            \n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    test_loss = running_loss / len(list(dataloader.dataset))\n    test_accuracy = accuracy = accuracy_score(y_true, y_pred)\n    precision, recall, test_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro',zero_division=0)\n    \n    print(f\"Test Loss: {test_loss:.6f} | Test Accuracy: {(test_accuracy * 100):.2f}% | Test F1-Score: {test_f1:.6f}\")\n    return test_loss, test_accuracy, test_f1\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:36:51.834787Z","iopub.execute_input":"2023-06-21T14:36:51.836104Z","iopub.status.idle":"2023-06-21T14:36:51.846832Z","shell.execute_reply.started":"2023-06-21T14:36:51.836071Z","shell.execute_reply":"2023-06-21T14:36:51.845557Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"# Função genérica para treinar, testar\ndef train_model(model_type, exp,model, train_dataloader, test_dataloader, criterion, optimizer, scheduler, device, num_epochs, ft):\n    model=model.to(device)\n    train_losses = []\n    train_accuracies = []\n    test_losses = []\n    test_accuracies = []\n\n    for epoch in range(num_epochs):\n        print('----------------------------------------------------------------------------')\n        train_loss, train_accuracy, train_f1 = train(model, train_dataloader, criterion, optimizer, scheduler, device, ft, epoch, exp, model_type)\n        test_loss, test_accuracy,test_f1 = test(model, test_dataloader, criterion, device)\n        data = {'Model Type': model_type,\n        'Exp': exp,\n        'Epoch': epoch+1,\n        'Train Accuracy': train_accuracy,\n        'Train Loss': train_loss,\n        'Train F1': train_f1,\n        'Test Accuracy': test_accuracy,\n        'Test Loss': test_loss,\n        'Test F1': test_f1}\n        new_row=pd.Series(data)\n        pd.concat([df, new_row], ignore_index=True)\n        train_losses.append(train_loss)\n        train_accuracies.append(train_accuracy)\n        test_losses.append(test_loss)\n        test_accuracies.append(test_accuracy)\n        print('\\n')\n        \n        \n        \n    return train_losses, train_accuracies, test_losses, test_accuracies\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:10:38.113060Z","iopub.execute_input":"2023-06-21T17:10:38.113505Z","iopub.status.idle":"2023-06-21T17:10:38.124498Z","shell.execute_reply.started":"2023-06-21T17:10:38.113474Z","shell.execute_reply":"2023-06-21T17:10:38.123281Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"def full_data_transform(model_type, data_fraction, batch_size):\n    # Transformações de dados\n    if model_type== 'convnext':\n        transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    elif model_type == 'vit':\n        transform = ViT_B_16_Weights.IMAGENET1K_V1.transforms()\n            \n            \n    local_arquivos='/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n    full_train_dataset = ImageFolder(local_arquivos + \"/train\", transform=transform)\n    full_test_dataset = ImageFolder(local_arquivos + \"/test\", transform=transform)\n            \n    # Determinar o número de objetos a serem selecionados\n    num_train_data = int(len(full_train_dataset) * data_fraction)\n    num_test_data = int(len(full_test_dataset) * data_fraction)\n    \n    \n\n    # Selecionar aleatoriamente os objetos para os conjuntos de dados\n    train_indices = random.sample(range(len(full_train_dataset)), num_train_data)\n    test_indices = random.sample(range(len(full_test_dataset)), num_test_data)\n\n    # Criar os datasets com a seleção aleatória de objetos\n    train_dataset = torch.utils.data.Subset(full_train_dataset, train_indices)\n    test_dataset = torch.utils.data.Subset(full_test_dataset, test_indices)\n    \n    # Criação dos dataloaders\n    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    test_dataloader = DataLoader(test_dataset, batch_size=int(batch_size/2), shuffle=False)\n        \n        \n    return train_dataloader, test_dataloader\n\ndef ft_data_transform(model_type, data_fraction, batch_size):\n    # Transformações de dados\n    if model_type== 'convnext':\n        transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n        \n    \n    elif model_type == 'vit':\n        transform = ViT_B_16_Weights.IMAGENET1K_V1.transforms()\n\n    local_arquivos='/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n    full_test_dataset = ImageFolder(local_arquivos + \"/test\", transform=transform)\n            \n    # Determinar o número de objetos a serem selecionados\n    num_test_data = int(len(full_test_dataset) * data_fraction)\n    \n\n    # Selecionar aleatoriamente os objetos para os conjuntos de dados\n    test_indices = random.sample(range(len(full_test_dataset)), num_test_data)\n\n    # Criar os datasets com a seleção aleatória de objetos\n    test_dataset = torch.utils.data.Subset(full_test_dataset, test_indices)\n    \n    # Criação dos dataloaders\n    test_dataloader = DataLoader(test_dataset, batch_size=int(batch_size/2), shuffle=False)\n\n    return test_dataloader","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:36:51.864092Z","iopub.execute_input":"2023-06-21T14:36:51.864775Z","iopub.status.idle":"2023-06-21T14:36:51.880443Z","shell.execute_reply.started":"2023-06-21T14:36:51.864737Z","shell.execute_reply":"2023-06-21T14:36:51.879346Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"def AutoAugment_transform(model_type, train_indices, batch_size):\n    if model_type== 'convnext':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.AutoAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n        \n    elif model_type == 'vit':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(224, interpolation=Image.BILINEAR),\n            transforms.CenterCrop(224),\n            transforms.AutoAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n        ])\n    local_arquivos='/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n    augmented_train_dataset = ImageFolder(local_arquivos + \"/train\", transform=augmentation_transforms)\n    augmented_train_dataset = torch.utils.data.Subset(augmented_train_dataset, train_indices)\n    augmented_train_dataloader = DataLoader(augmented_train_dataset, batch_size=batch_size, shuffle=True)\n    \n    return augmented_train_dataloader\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:36:51.881723Z","iopub.execute_input":"2023-06-21T14:36:51.882418Z","iopub.status.idle":"2023-06-21T14:36:51.894772Z","shell.execute_reply.started":"2023-06-21T14:36:51.882385Z","shell.execute_reply":"2023-06-21T14:36:51.894016Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"def RandAugment_transform(model_type, train_indices, batch_size):\n    if model_type== 'convnext':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.RandAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    \n    elif model_type == 'vit':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(224, interpolation=Image.BILINEAR),\n            transforms.CenterCrop(224),\n            transforms.RandAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n        ])\n        \n    local_arquivos='/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n    augmented_train_dataset = ImageFolder(local_arquivos + \"/train\", transform=augmentation_transforms)\n    augmented_train_dataset = torch.utils.data.Subset(augmented_train_dataset, train_indices)\n    augmented_train_dataloader = DataLoader(augmented_train_dataset, batch_size=batch_size, shuffle=True)\n    \n    return augmented_train_dataloader\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:36:51.896141Z","iopub.execute_input":"2023-06-21T14:36:51.896923Z","iopub.status.idle":"2023-06-21T14:36:51.909418Z","shell.execute_reply.started":"2023-06-21T14:36:51.896858Z","shell.execute_reply":"2023-06-21T14:36:51.908708Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"def Auto_RandAugment_transform(model_type, train_indices, batch_size):\n    if model_type== 'convnext':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.AutoAugment(),\n            transforms.RandAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    \n    elif model_type == 'vit':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(224, interpolation=Image.BILINEAR),\n            transforms.CenterCrop(224),\n            transforms.AutoAugment(),\n            transforms.RandAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n        ])\n        \n    local_arquivos='/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n    augmented_train_dataset = ImageFolder(local_arquivos + \"/train\", transform=augmentation_transforms)\n    augmented_train_dataset = torch.utils.data.Subset(augmented_train_dataset, train_indices)\n    augmented_train_dataloader = DataLoader(augmented_train_dataset, batch_size=batch_size, shuffle=True)\n    \n    return augmented_train_dataloader","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:36:51.910744Z","iopub.execute_input":"2023-06-21T14:36:51.911788Z","iopub.status.idle":"2023-06-21T14:36:51.924849Z","shell.execute_reply.started":"2023-06-21T14:36:51.911756Z","shell.execute_reply":"2023-06-21T14:36:51.924097Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":"#**Aplicando o protocolo experimental para os seguintes cenários:\n\n#Aumentos de dados: AutoAugment, RandAugment e Mixup\n\n#Fine Tuning: Com e sem\n\n#1 - Sem Fine Tuning\n\n#2 - Com Fine Tuning\n\n#3 - Sem Fine Tuning e com AutoAugment\n\n#4 - Com Fine Tuning e com AutoAugment\n\n#5 - Sem Fine Tuning e com RandAugment\n\n#6 - Com Fine Tuning e com RandAugment\n\n#7 - Sem Fine Tuning e com AutoAugment e RandAugment\n\n#8 - Com Fine Tuning e com AutoAugment e RandAugment\n","metadata":{}},{"cell_type":"code","source":"def run_scenario(model_type, scenario, data_fraction, num_epochs=10, batch_size=32, learning_rate=0.001):\n    num_classes = 2  \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    num_train_data = int((100000) * data_fraction)\n    num_test_data = int((20000) * data_fraction)\n    \n    train_indices = random.sample(range(100000), num_train_data)\n    test_indices = random.sample(range(20000), num_test_data)\n    \n    print(f'Número de objetos de treino: {num_train_data}')\n    print(f'Número de objetos de teste: {num_test_data}')\n    print(\"============================================================================\")\n    \n    if scenario == 1:\n        \n        train_dataloader, test_dataloader= full_data_transform(model_type, data_fraction, batch_size)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n\n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n        \n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 1 - ConvNeXt (Sem Fine-Tuning)\")\n        elif model_type == 'vit':\n            print(\"Experimento 1 - ViT (Sem Fine-Tuning)\")\n        \n        train_losses, train_accuracies, test_losses, test_accuracies = train_model(model_type,1, model, train_dataloader, test_dataloader,\n                                                                                    criterion, optimizer, scheduler, device, 1, False)\n    elif scenario == 2:\n        \n        train_dataloader, test_dataloader= full_data_transform(model_type, data_fraction, batch_size)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n\n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n             print(\"Experimento 2 - ConvNeXt (Com Fine-Tuning)\")\n        elif model_type == 'vit':\n            print(\"Experimento 2 - ViT (Com Fine-Tuning)\")\n        \n        train_losses, train_accuracies, test_losses, test_accuracies = train_model(model_type,2, model, train_dataloader, test_dataloader,\n                                                                                    criterion, optimizer, scheduler, device, num_epochs, True)\n    elif scenario == 3:\n        \n        augmented_train_dataloader = AutoAugment_transform(model_type, train_indices, batch_size)\n        test_dataloader=ft_data_transform(model_type, data_fraction, batch_size)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n\n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 3 - ConvNeXt (Sem Fine-Tuning e com AutoAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 3 - ViT (Sem Fine-Tuning e com AutoAugment)\")\n        \n        \n        train_losses, train_accuracies, test_losses, test_accuracies = train_model(model_type,3, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, 1, False)\n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n\n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 4 - ConvNeXt (Com Fine-Tuning e com AutoAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 4 - ViT (Com Fine-Tuning e com AutoAugment)\")\n        \n        train_losses, train_accuracies, test_losses, test_accuracies = train_model(model_type,4, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, num_epochs, True)\n    \n    elif scenario == 4:\n        augmented_train_dataloader = RandAugment_transform(model_type, train_indices, batch_size)\n        test_dataloader=ft_data_transform(model_type, data_fraction, batch_size)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n\n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n  \n        if model_type == 'convnext':\n            print(\"Experimento 5 - ConvNeXt (Sem Fine-Tuning e com RandAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 5 - ViT (Sem Fine-Tuning e com RandAugment)\")    \n        \n        train_losses, train_accuracies, test_losses, test_accuracies = train_model(model_type,5, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, 1, False)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n\n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 6 - ConvNeXt (Com Fine-Tuning e com RandAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 6 - ViT (Com Fine-Tuning e com RandAugment)\")\n        \n        \n        train_losses, train_accuracies, test_losses, test_accuracies = train_model(model_type,6, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, num_epochs, True) \n\n    elif scenario == 5:\n        augmented_train_dataloader = Auto_RandAugment_transform(model_type, train_indices, batch_size)\n        test_dataloader=ft_data_transform(model_type, data_fraction, batch_size)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n\n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 7 - ConvNeXt (Sem Fine-Tuning e com RandAugment e AutoAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 7 - ViT (Sem Fine-Tuning e com RandAugment e AutoAugment)\")\n            \n        train_losses, train_accuracies, test_losses, test_accuracies = train_model(model_type,7, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, 1, False)\n      \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n\n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 7 - ConvNeXt (Com Fine-Tuning e com RandAugment e AutoAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 7 - ViT (Com Fine-Tuning e com RandAugment e AutoAugment)\")\n\n        train_losses, train_accuracies, test_losses, test_accuracies = train_model(model_type,8, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, num_epochs, True)\n    else:\n        raise ValueError(\"O parâmetro 'scenario' deve ser um número entre 1 e 5.\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:36:51.926239Z","iopub.execute_input":"2023-06-21T14:36:51.927220Z","iopub.status.idle":"2023-06-21T14:36:51.969274Z","shell.execute_reply.started":"2023-06-21T14:36:51.927186Z","shell.execute_reply":"2023-06-21T14:36:51.968236Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"run_scenario('convnext',1,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:36:51.970947Z","iopub.execute_input":"2023-06-21T14:36:51.971340Z","iopub.status.idle":"2023-06-21T14:39:55.398223Z","shell.execute_reply.started":"2023-06-21T14:36:51.971308Z","shell.execute_reply":"2023-06-21T14:39:55.397190Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stdout","text":"Número de objetos de treino: 10000\nNúmero de objetos de teste: 2000\n============================================================================\nExperimento 1 - ConvNeXt (Sem Fine-Tuning)\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 1]: 100%|██████████| 625/625 [02:04<00:00,  5.01it/s, loss=0.68] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.043967 | Train Accuracy: 50.09% | Train F1-Score: 0.419077\nTest Loss: 0.086724 | Test Accuracy: 53.50% | Test F1-Score: 0.454081\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"run_scenario('convnext',2,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T14:39:55.399921Z","iopub.execute_input":"2023-06-21T14:39:55.400529Z","iopub.status.idle":"2023-06-21T15:18:43.855509Z","shell.execute_reply.started":"2023-06-21T14:39:55.400481Z","shell.execute_reply":"2023-06-21T15:18:43.854417Z"},"trusted":true},"execution_count":119,"outputs":[{"name":"stdout","text":"Número de objetos de treino: 10000\nNúmero de objetos de teste: 2000\n============================================================================\nExperimento 2 - ConvNeXt (Com Fine-Tuning)\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 1]: 100%|██████████| 625/625 [04:02<00:00,  2.58it/s, loss=0.00201] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.008061 | Train Accuracy: 94.23% | Train F1-Score: 0.942273\nTest Loss: 0.001043 | Test Accuracy: 99.65% | Test F1-Score: 0.996500\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 2]: 100%|██████████| 625/625 [03:27<00:00,  3.02it/s, loss=0.00013] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.001112 | Train Accuracy: 99.40% | Train F1-Score: 0.993999\nTest Loss: 0.001576 | Test Accuracy: 99.50% | Test F1-Score: 0.995000\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 3]: 100%|██████████| 625/625 [03:24<00:00,  3.05it/s, loss=9.69e-5] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000070 | Train Accuracy: 99.98% | Train F1-Score: 0.999800\nTest Loss: 0.000397 | Test Accuracy: 99.85% | Test F1-Score: 0.998500\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 4]: 100%|██████████| 625/625 [03:24<00:00,  3.06it/s, loss=0.000135]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000014 | Train Accuracy: 100.00% | Train F1-Score: 1.000000\nTest Loss: 0.000393 | Test Accuracy: 99.85% | Test F1-Score: 0.998500\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 5]: 100%|██████████| 625/625 [03:24<00:00,  3.06it/s, loss=0.000108]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000011 | Train Accuracy: 100.00% | Train F1-Score: 1.000000\nTest Loss: 0.000392 | Test Accuracy: 99.85% | Test F1-Score: 0.998500\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 6]: 100%|██████████| 625/625 [03:25<00:00,  3.05it/s, loss=7.29e-5] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000010 | Train Accuracy: 100.00% | Train F1-Score: 1.000000\nTest Loss: 0.000392 | Test Accuracy: 99.85% | Test F1-Score: 0.998500\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 7]: 100%|██████████| 625/625 [03:24<00:00,  3.06it/s, loss=0.000119]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000010 | Train Accuracy: 100.00% | Train F1-Score: 1.000000\nTest Loss: 0.000392 | Test Accuracy: 99.85% | Test F1-Score: 0.998500\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 8]: 100%|██████████| 625/625 [03:24<00:00,  3.06it/s, loss=0.000177]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000010 | Train Accuracy: 100.00% | Train F1-Score: 1.000000\nTest Loss: 0.000392 | Test Accuracy: 99.85% | Test F1-Score: 0.998500\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 9]: 100%|██████████| 625/625 [03:24<00:00,  3.05it/s, loss=0.00011] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000010 | Train Accuracy: 100.00% | Train F1-Score: 1.000000\nTest Loss: 0.000392 | Test Accuracy: 99.85% | Test F1-Score: 0.998500\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 10]: 100%|██████████| 625/625 [03:24<00:00,  3.05it/s, loss=0.00026] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000010 | Train Accuracy: 100.00% | Train F1-Score: 1.000000\nTest Loss: 0.000392 | Test Accuracy: 99.85% | Test F1-Score: 0.998500\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"run_scenario('convnext',3,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T15:18:43.857299Z","iopub.execute_input":"2023-06-21T15:18:43.857932Z","iopub.status.idle":"2023-06-21T16:02:14.747361Z","shell.execute_reply.started":"2023-06-21T15:18:43.857892Z","shell.execute_reply":"2023-06-21T16:02:14.746245Z"},"trusted":true},"execution_count":120,"outputs":[{"name":"stdout","text":"Número de objetos de treino: 10000\nNúmero de objetos de teste: 2000\n============================================================================\nExperimento 3 - ConvNeXt (Sem Fine-Tuning e com AutoAugment)\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 1]: 100%|██████████| 625/625 [02:09<00:00,  4.83it/s, loss=0.692]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.044430 | Train Accuracy: 42.71% | Train F1-Score: 0.403748\nTest Loss: 0.088653 | Test Accuracy: 44.85% | Test F1-Score: 0.409335\n\n\nExperimento 4 - ConvNeXt (Com Fine-Tuning e com AutoAugment)\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 1]: 100%|██████████| 625/625 [03:37<00:00,  2.87it/s, loss=0.0147] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.011999 | Train Accuracy: 91.78% | Train F1-Score: 0.917794\nTest Loss: 0.003812 | Test Accuracy: 99.05% | Test F1-Score: 0.990484\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 2]: 100%|██████████| 625/625 [03:38<00:00,  2.87it/s, loss=0.0233]  \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.003011 | Train Accuracy: 98.21% | Train F1-Score: 0.982100\nTest Loss: 0.002075 | Test Accuracy: 99.55% | Test F1-Score: 0.995494\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 3]: 100%|██████████| 625/625 [03:38<00:00,  2.87it/s, loss=0.00647] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.001008 | Train Accuracy: 99.50% | Train F1-Score: 0.995000\nTest Loss: 0.000612 | Test Accuracy: 99.90% | Test F1-Score: 0.998999\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 4]: 100%|██████████| 625/625 [03:38<00:00,  2.86it/s, loss=0.00985] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000816 | Train Accuracy: 99.54% | Train F1-Score: 0.995400\nTest Loss: 0.000605 | Test Accuracy: 99.90% | Test F1-Score: 0.998999\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 5]: 100%|██████████| 625/625 [03:38<00:00,  2.86it/s, loss=0.000443]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000531 | Train Accuracy: 99.70% | Train F1-Score: 0.997000\nTest Loss: 0.000500 | Test Accuracy: 99.95% | Test F1-Score: 0.999499\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 6]: 100%|██████████| 625/625 [03:38<00:00,  2.86it/s, loss=0.000488]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000590 | Train Accuracy: 99.70% | Train F1-Score: 0.997000\nTest Loss: 0.000504 | Test Accuracy: 99.95% | Test F1-Score: 0.999499\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 7]: 100%|██████████| 625/625 [03:38<00:00,  2.86it/s, loss=0.000699]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000428 | Train Accuracy: 99.84% | Train F1-Score: 0.998400\nTest Loss: 0.000492 | Test Accuracy: 99.95% | Test F1-Score: 0.999499\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 8]: 100%|██████████| 625/625 [03:37<00:00,  2.88it/s, loss=0.0119]  \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000448 | Train Accuracy: 99.79% | Train F1-Score: 0.997900\nTest Loss: 0.000489 | Test Accuracy: 99.90% | Test F1-Score: 0.998999\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 9]: 100%|██████████| 625/625 [03:36<00:00,  2.88it/s, loss=0.000663]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000547 | Train Accuracy: 99.68% | Train F1-Score: 0.996800\nTest Loss: 0.000488 | Test Accuracy: 99.90% | Test F1-Score: 0.998999\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 10]: 100%|██████████| 625/625 [03:36<00:00,  2.88it/s, loss=0.000633]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000467 | Train Accuracy: 99.79% | Train F1-Score: 0.997900\nTest Loss: 0.000487 | Test Accuracy: 99.90% | Test F1-Score: 0.998999\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"run_scenario('convnext',4,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:02:14.748925Z","iopub.execute_input":"2023-06-21T16:02:14.750137Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Número de objetos de treino: 10000\nNúmero de objetos de teste: 2000\n============================================================================\nExperimento 5 - ConvNeXt (Sem Fine-Tuning e com RandAugment)\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 1]: 100%|██████████| 625/625 [02:08<00:00,  4.88it/s, loss=0.669]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.043463 | Train Accuracy: 52.12% | Train F1-Score: 0.478612\nTest Loss: 0.087252 | Test Accuracy: 51.85% | Test F1-Score: 0.472090\n\n\nExperimento 6 - ConvNeXt (Com Fine-Tuning e com RandAugment)\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 1]: 100%|██████████| 625/625 [03:40<00:00,  2.84it/s, loss=0.02]   \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.011362 | Train Accuracy: 92.12% | Train F1-Score: 0.921172\nTest Loss: 0.003438 | Test Accuracy: 98.95% | Test F1-Score: 0.989497\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 2]: 100%|██████████| 625/625 [03:41<00:00,  2.83it/s, loss=0.00235] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.002479 | Train Accuracy: 98.44% | Train F1-Score: 0.984400\nTest Loss: 0.002222 | Test Accuracy: 99.50% | Test F1-Score: 0.994999\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 3]: 100%|██████████| 625/625 [03:39<00:00,  2.84it/s, loss=0.000256]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000507 | Train Accuracy: 99.69% | Train F1-Score: 0.996900\nTest Loss: 0.000758 | Test Accuracy: 99.80% | Test F1-Score: 0.998000\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 4]: 100%|██████████| 625/625 [03:40<00:00,  2.83it/s, loss=0.000181]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000312 | Train Accuracy: 99.80% | Train F1-Score: 0.998000\nTest Loss: 0.000504 | Test Accuracy: 99.90% | Test F1-Score: 0.999000\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 5]: 100%|██████████| 625/625 [03:40<00:00,  2.84it/s, loss=0.000115]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000254 | Train Accuracy: 99.89% | Train F1-Score: 0.998900\nTest Loss: 0.000692 | Test Accuracy: 99.80% | Test F1-Score: 0.998000\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 6]: 100%|██████████| 625/625 [03:39<00:00,  2.84it/s, loss=0.000915]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000276 | Train Accuracy: 99.84% | Train F1-Score: 0.998400\nTest Loss: 0.000545 | Test Accuracy: 99.90% | Test F1-Score: 0.999000\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 7]: 100%|██████████| 625/625 [03:38<00:00,  2.86it/s, loss=0.000308]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000174 | Train Accuracy: 99.94% | Train F1-Score: 0.999400\nTest Loss: 0.000544 | Test Accuracy: 99.90% | Test F1-Score: 0.999000\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 8]: 100%|██████████| 625/625 [03:41<00:00,  2.83it/s, loss=9.94e-5] \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000315 | Train Accuracy: 99.84% | Train F1-Score: 0.998400\nTest Loss: 0.000550 | Test Accuracy: 99.90% | Test F1-Score: 0.999000\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 9]: 100%|██████████| 625/625 [03:40<00:00,  2.84it/s, loss=0.000269]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000174 | Train Accuracy: 99.97% | Train F1-Score: 0.999700\nTest Loss: 0.000549 | Test Accuracy: 99.90% | Test F1-Score: 0.999000\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 10]:  87%|████████▋ | 544/625 [03:11<00:28,  2.86it/s, loss=0.00151] ","output_type":"stream"}]},{"cell_type":"code","source":"run_scenario('convnext',5,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:32:45.783580Z","iopub.execute_input":"2023-06-21T17:32:45.784060Z","iopub.status.idle":"2023-06-21T17:33:53.937585Z","shell.execute_reply.started":"2023-06-21T17:32:45.784025Z","shell.execute_reply":"2023-06-21T17:33:53.935910Z"},"trusted":true},"execution_count":127,"outputs":[{"name":"stdout","text":"Número de objetos de treino: 10000\nNúmero de objetos de teste: 2000\n============================================================================\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[127], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_scenario\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconvnext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[117], line 185\u001b[0m, in \u001b[0;36mrun_scenario\u001b[0;34m(model_type, scenario, data_fraction, num_epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m    182\u001b[0m augmented_train_dataloader \u001b[38;5;241m=\u001b[39m Auto_RandAugment_transform(model_type, train_indices, batch_size)\n\u001b[1;32m    183\u001b[0m test_dataloader\u001b[38;5;241m=\u001b[39mft_data_transform(model_type, data_fraction, batch_size)\n\u001b[0;32m--> 185\u001b[0m augmented_train_dataset \u001b[38;5;241m=\u001b[39m ImageFolder(local_arquivos \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, transform\u001b[38;5;241m=\u001b[39m\u001b[43maugmentation_transforms\u001b[49m)\n\u001b[1;32m    186\u001b[0m augmented_train_dataset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mSubset(augmented_train_dataset, train_indices)\n\u001b[1;32m    187\u001b[0m augmented_train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(augmented_train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mNameError\u001b[0m: name 'augmentation_transforms' is not defined"],"ename":"NameError","evalue":"name 'augmentation_transforms' is not defined","output_type":"error"}]},{"cell_type":"code","source":"run_scenario('vit',1,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:47:10.778190Z","iopub.status.idle":"2023-06-21T16:47:10.779181Z","shell.execute_reply.started":"2023-06-21T16:47:10.778991Z","shell.execute_reply":"2023-06-21T16:47:10.779009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',2,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:47:10.780786Z","iopub.status.idle":"2023-06-21T16:47:10.781455Z","shell.execute_reply.started":"2023-06-21T16:47:10.781210Z","shell.execute_reply":"2023-06-21T16:47:10.781233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',3,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:47:10.783033Z","iopub.status.idle":"2023-06-21T16:47:10.784024Z","shell.execute_reply.started":"2023-06-21T16:47:10.783724Z","shell.execute_reply":"2023-06-21T16:47:10.783750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',4,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:47:10.785543Z","iopub.status.idle":"2023-06-21T16:47:10.786033Z","shell.execute_reply.started":"2023-06-21T16:47:10.785771Z","shell.execute_reply":"2023-06-21T16:47:10.785794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',5,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:47:10.788432Z","iopub.status.idle":"2023-06-21T16:47:10.789274Z","shell.execute_reply.started":"2023-06-21T16:47:10.788989Z","shell.execute_reply":"2023-06-21T16:47:10.789017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:19.014915Z","iopub.execute_input":"2023-06-21T17:02:19.015546Z","iopub.status.idle":"2023-06-21T17:02:19.042641Z","shell.execute_reply.started":"2023-06-21T17:02:19.015512Z","shell.execute_reply":"2023-06-21T17:02:19.040402Z"},"trusted":true},"execution_count":123,"outputs":[{"name":"stdout","text":"     Modelo  Experimento  Epoch  Train ACC  Train Loss  Train F1  Test ACC  \\\n0  convnext            6      1     0.9212    0.011362  0.921172    0.9895   \n1  convnext            6      2     0.9844    0.002479  0.984400    0.9950   \n2  convnext            6      3     0.9969    0.000507  0.996900    0.9980   \n3  convnext            6      4     0.9980    0.000312  0.998000    0.9990   \n4  convnext            6      5     0.9989    0.000254  0.998900    0.9980   \n5  convnext            6      6     0.9984    0.000276  0.998400    0.9990   \n6  convnext            6      7     0.9994    0.000174  0.999400    0.9990   \n7  convnext            6      8     0.9984    0.000315  0.998400    0.9990   \n8  convnext            6      9     0.9997    0.000174  0.999700    0.9990   \n9  convnext            6     10     0.9984    0.000264  0.998400    0.9990   \n\n   Test Loss   Test F1  \n0   0.003438  0.989497  \n1   0.002222  0.994999  \n2   0.000758  0.998000  \n3   0.000504  0.999000  \n4   0.000692  0.998000  \n5   0.000545  0.999000  \n6   0.000544  0.999000  \n7   0.000550  0.999000  \n8   0.000549  0.999000  \n9   0.000549  0.999000  \n","output_type":"stream"}]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:03:43.314356Z","iopub.execute_input":"2023-06-21T17:03:43.314768Z","iopub.status.idle":"2023-06-21T17:03:43.335595Z","shell.execute_reply.started":"2023-06-21T17:03:43.314737Z","shell.execute_reply":"2023-06-21T17:03:43.334641Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"print(mean_df)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:03:53.568992Z","iopub.execute_input":"2023-06-21T17:03:53.569383Z","iopub.status.idle":"2023-06-21T17:03:53.583108Z","shell.execute_reply.started":"2023-06-21T17:03:53.569354Z","shell.execute_reply":"2023-06-21T17:03:53.582081Z"},"trusted":true},"execution_count":125,"outputs":[{"name":"stdout","text":"                      Epoch  Train ACC  Train Loss  Train F1  Test ACC  \\\nModelo   Experimento                                                     \nconvnext 6              5.5    0.98937    0.001612  0.989367   0.99745   \n\n                      Test Loss  Test F1  \nModelo   Experimento                      \nconvnext 6             0.001035  0.99745  \n","output_type":"stream"}]}]}