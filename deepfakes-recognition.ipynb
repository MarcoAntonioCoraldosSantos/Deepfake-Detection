{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Algoritmo Para Detecção de Imagens de Faces DeepFakes Por Meio de Aprendizado de Máquina**\n## Universidade Federal de São Paulo - UNIFESP\n\n### Disciplina: Inteligência Artificial\n### Professor: Fábio Faria\n### Integrantes:\n###  -  Marco Antonio Coral dos Santos\n###  -  Raphael Damasceno Rocha de Moraes","metadata":{}},{"cell_type":"markdown","source":"# **1. Introdução**","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-21T20:51:23.698936Z","iopub.execute_input":"2023-06-21T20:51:23.699335Z","iopub.status.idle":"2023-06-21T20:51:23.710770Z","shell.execute_reply.started":"2023-06-21T20:51:23.699299Z","shell.execute_reply":"2023-06-21T20:51:23.709886Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport random\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport seaborn as sb\nimport torch \nfrom torchvision import models\nfrom torch import nn\nfrom torch import optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.models.vision_transformer import vit_b_16, ViT_B_16_Weights\nfrom torchvision.utils import make_grid\nfrom torch.autograd import Variable\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score, accuracy_score, precision_recall_fscore_support\nimport shutil\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ncode_dir = \"/kaggle/working/code\"\nmodel_dir = \"/kaggle/working/model\"\noutput_dir = \"/kaggle/working/output\"\n\nif not os.path.exists(code_dir):\n    os.mkdir(code_dir)\n\nif not os.path.exists(model_dir):\n    os.mkdir(model_dir)\n\nif not os.path.exists(output_dir):\n    os.mkdir(output_dir)\n    \nshutil.copyfile(src=\"/kaggle/input/modelos/convnext.py\", \n                dst=\"/kaggle/working/code/convnext.py\")\nshutil.copyfile(src=\"/kaggle/input/modelos/convnext_tiny_1k_224_ema.pth\", \n                dst=\"/kaggle/working/model/convnext_tiny_1k_224_ema.pth\")\nshutil.copyfile(src=\"/kaggle/input/modelos/vit_b_16-c867db91.pth\", \n                dst=\"/kaggle/working/model/vit_b_16-c867db91.pth\")\n\nos.chdir(\"/kaggle/working/code\")\n\n\nfrom convnext import ConvNeXt\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:23.712425Z","iopub.execute_input":"2023-06-21T20:51:23.712967Z","iopub.status.idle":"2023-06-21T20:51:34.887213Z","shell.execute_reply.started":"2023-06-21T20:51:23.712935Z","shell.execute_reply":"2023-06-21T20:51:34.886266Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# **2. Banco de Dados**","metadata":{}},{"cell_type":"code","source":"local_arquivos='/kaggle/input/140k-real-and-fake-faces'\ntreino = pd.read_csv(local_arquivos + \"/train.csv\")\nteste = pd.read_csv(local_arquivos + \"/test.csv\")\nprint(teste.shape)\nprint(treino.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:34.891528Z","iopub.execute_input":"2023-06-21T20:51:34.891802Z","iopub.status.idle":"2023-06-21T20:51:35.375983Z","shell.execute_reply.started":"2023-06-21T20:51:34.891776Z","shell.execute_reply":"2023-06-21T20:51:35.375017Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"(20000, 6)\n(100000, 6)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **2.1. Arquiteturas de Rede**","metadata":{}},{"cell_type":"code","source":"#Instanciando o modelo ConvNeXt \ndef ConvNeXt_model():\n    model_conv=ConvNeXt()\n    state_dict = torch.load('/kaggle/working/model/convnext_tiny_1k_224_ema.pth')\n    model_conv.load_state_dict(state_dict[\"model\"])\n    \n    return model_conv\n\ndef ViT_model():\n    model_vit=vit_b_16(pretrained=True)\n    return model_vit\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:35.377251Z","iopub.execute_input":"2023-06-21T20:51:35.377603Z","iopub.status.idle":"2023-06-21T20:51:35.383696Z","shell.execute_reply.started":"2023-06-21T20:51:35.377570Z","shell.execute_reply":"2023-06-21T20:51:35.382596Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:35.386715Z","iopub.execute_input":"2023-06-21T20:51:35.387045Z","iopub.status.idle":"2023-06-21T20:51:35.423295Z","shell.execute_reply.started":"2023-06-21T20:51:35.387015Z","shell.execute_reply":"2023-06-21T20:51:35.422018Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"  criterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:35.426613Z","iopub.execute_input":"2023-06-21T20:51:35.427210Z","iopub.status.idle":"2023-06-21T20:51:35.437494Z","shell.execute_reply.started":"2023-06-21T20:51:35.427177Z","shell.execute_reply":"2023-06-21T20:51:35.436350Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:35.439417Z","iopub.execute_input":"2023-06-21T20:51:35.439807Z","iopub.status.idle":"2023-06-21T20:51:35.451301Z","shell.execute_reply.started":"2023-06-21T20:51:35.439777Z","shell.execute_reply":"2023-06-21T20:51:35.450364Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_acc, teste_acc, train_loss, teste_loss = [], [], [], []\ntrain_precision, teste_precision, train_recall, teste_recall = [], [], [], []\ntrain_f1, teste_f1 = [], []\ndf = pd.DataFrame(columns=['Modelo','Experimento','Epoch', 'Train ACC', 'Train Loss', 'Train F1', 'Test ACC', 'Test Loss', 'Test F1'])","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:35.452860Z","iopub.execute_input":"2023-06-21T20:51:35.454525Z","iopub.status.idle":"2023-06-21T20:51:35.468261Z","shell.execute_reply.started":"2023-06-21T20:51:35.454490Z","shell.execute_reply":"2023-06-21T20:51:35.466829Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# **3. Metodologia**","metadata":{}},{"cell_type":"markdown","source":"## **3.1. Aumento de Dados**","metadata":{}},{"cell_type":"markdown","source":"### **3.1.1. Processamento das Imagens**","metadata":{}},{"cell_type":"code","source":"def full_data_transform(model_type, data_fraction, batch_size):\n    # Transformações de dados\n    if model_type== 'convnext':\n        transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    elif model_type == 'vit':\n        transform = ViT_B_16_Weights.IMAGENET1K_V1.transforms()\n            \n            \n    local_arquivos='/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n    full_train_dataset = ImageFolder(local_arquivos + \"/train\", transform=transform)\n    full_test_dataset = ImageFolder(local_arquivos + \"/test\", transform=transform)\n            \n    # Determinar o número de objetos a serem selecionados\n    num_train_data = int(len(full_train_dataset) * data_fraction)\n    num_test_data = int(len(full_test_dataset) * data_fraction)\n    \n    \n\n    # Selecionar aleatoriamente os objetos para os conjuntos de dados\n    train_indices = random.sample(range(len(full_train_dataset)), num_train_data)\n    test_indices = random.sample(range(len(full_test_dataset)), num_test_data)\n\n    # Criar os datasets com a seleção aleatória de objetos\n    train_dataset = torch.utils.data.Subset(full_train_dataset, train_indices)\n    test_dataset = torch.utils.data.Subset(full_test_dataset, test_indices)\n    \n    # Criação dos dataloaders\n    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    test_dataloader = DataLoader(test_dataset, batch_size=int(batch_size/2), shuffle=False)\n        \n        \n    return train_dataloader, test_dataloader\n\ndef ft_data_transform(model_type, data_fraction, batch_size):\n    # Transformações de dados\n    if model_type== 'convnext':\n        transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n        \n    \n    elif model_type == 'vit':\n        transform = ViT_B_16_Weights.IMAGENET1K_V1.transforms()\n\n    local_arquivos='/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n    full_test_dataset = ImageFolder(local_arquivos + \"/test\", transform=transform)\n            \n    # Determinar o número de objetos a serem selecionados\n    num_test_data = int(len(full_test_dataset) * data_fraction)\n    \n\n    # Selecionar aleatoriamente os objetos para os conjuntos de dados\n    test_indices = random.sample(range(len(full_test_dataset)), num_test_data)\n\n    # Criar os datasets com a seleção aleatória de objetos\n    test_dataset = torch.utils.data.Subset(full_test_dataset, test_indices)\n    \n    # Criação dos dataloaders\n    test_dataloader = DataLoader(test_dataset, batch_size=int(batch_size/2), shuffle=False)\n\n    return test_dataloader","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:35.470377Z","iopub.execute_input":"2023-06-21T20:51:35.471761Z","iopub.status.idle":"2023-06-21T20:51:35.488981Z","shell.execute_reply.started":"2023-06-21T20:51:35.471730Z","shell.execute_reply":"2023-06-21T20:51:35.488030Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### **3.1.2. AutoAugment**","metadata":{}},{"cell_type":"code","source":"def AutoAugment_transform(model_type, train_indices, batch_size):\n    if model_type== 'convnext':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.AutoAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n        \n    elif model_type == 'vit':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(224, interpolation=Image.BILINEAR),\n            transforms.CenterCrop(224),\n            transforms.AutoAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n        ])\n    local_arquivos='/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n    augmented_train_dataset = ImageFolder(local_arquivos + \"/train\", transform=augmentation_transforms)\n    augmented_train_dataset = torch.utils.data.Subset(augmented_train_dataset, train_indices)\n    augmented_train_dataloader = DataLoader(augmented_train_dataset, batch_size=batch_size, shuffle=True)\n    \n    return augmented_train_dataloader\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:35.490653Z","iopub.execute_input":"2023-06-21T20:51:35.491052Z","iopub.status.idle":"2023-06-21T20:51:35.502186Z","shell.execute_reply.started":"2023-06-21T20:51:35.491004Z","shell.execute_reply":"2023-06-21T20:51:35.501157Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### **3.1.3. RandAugment**","metadata":{}},{"cell_type":"code","source":"def RandAugment_transform(model_type, train_indices, batch_size):\n    if model_type== 'convnext':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.RandAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    \n    elif model_type == 'vit':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(224, interpolation=Image.BILINEAR),\n            transforms.CenterCrop(224),\n            transforms.RandAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n        ])\n        \n    local_arquivos='/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n    augmented_train_dataset = ImageFolder(local_arquivos + \"/train\", transform=augmentation_transforms)\n    augmented_train_dataset = torch.utils.data.Subset(augmented_train_dataset, train_indices)\n    augmented_train_dataloader = DataLoader(augmented_train_dataset, batch_size=batch_size, shuffle=True)\n    \n    return augmented_train_dataloader\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:35.506742Z","iopub.execute_input":"2023-06-21T20:51:35.507250Z","iopub.status.idle":"2023-06-21T20:51:35.515670Z","shell.execute_reply.started":"2023-06-21T20:51:35.507213Z","shell.execute_reply":"2023-06-21T20:51:35.514838Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### **3.1.4. Auto+Rand Augment**","metadata":{}},{"cell_type":"code","source":"def Auto_RandAugment_transform(model_type, train_indices, batch_size):\n    if model_type== 'convnext':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.AutoAugment(),\n            transforms.RandAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    \n    elif model_type == 'vit':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(224, interpolation=Image.BILINEAR),\n            transforms.CenterCrop(224),\n            transforms.AutoAugment(),\n            transforms.RandAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n        ])\n        \n    local_arquivos='/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n    augmented_train_dataset = ImageFolder(local_arquivos + \"/train\", transform=augmentation_transforms)\n    augmented_train_dataset = torch.utils.data.Subset(augmented_train_dataset, train_indices)\n    augmented_train_dataloader = DataLoader(augmented_train_dataset, batch_size=batch_size, shuffle=True)\n    \n    return augmented_train_dataloader","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:35.517078Z","iopub.execute_input":"2023-06-21T20:51:35.517456Z","iopub.status.idle":"2023-06-21T20:51:35.528126Z","shell.execute_reply.started":"2023-06-21T20:51:35.517426Z","shell.execute_reply":"2023-06-21T20:51:35.527141Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## **3.2. Treinamento e Teste**","metadata":{}},{"cell_type":"code","source":" # Função de treino genérica\ndef train(model, dataloader, criterion, optimizer, scheduler, device, ft, epoch, exp, model_type):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    y_true,y_pred=[], []\n    \n    loop = tqdm(enumerate(dataloader), total=len(dataloader))\n    for batch_idx, (images, labels) in loop:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        if ft==False:\n            for param in model.parameters():\n                param.requires_grad=False\n                \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            optimizer.step()\n            \n            for param in model.parameters():\n                param.requires_grad=True\n        else:    \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n                \n        running_loss += loss.item()\n        predicted = outputs.argmax(dim = 1)\n    \n        y_true.extend(labels.cpu().tolist())\n        y_pred.extend(predicted.cpu().tolist())\n\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n        \n        loop.set_description(f\"[Epoch {(epoch+1)}]\")\n        loop.set_postfix(loss=loss.item())\n        \n    if scheduler:\n        scheduler.step()\n        \n    train_loss = running_loss / len(dataloader.dataset)  \n    accuracy = accuracy_score(y_true, y_pred)\n    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro',zero_division=0)\n\n    print(f\"Train Loss: {train_loss:.6f} | Train Accuracy: {(accuracy * 100):.2f}% | Train F1-Score: {f1:.6f}\")\n    \n    model_name= f'model{model_type}_params_exp{exp}'\n    torch.save(model.state_dict(), os.path.join('/kaggle/working/model', 'model_params.pth'))\n   \n    return train_loss, accuracy, f1","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:35.529541Z","iopub.execute_input":"2023-06-21T20:51:35.530021Z","iopub.status.idle":"2023-06-21T20:51:35.544627Z","shell.execute_reply.started":"2023-06-21T20:51:35.529990Z","shell.execute_reply":"2023-06-21T20:51:35.543764Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Função de teste genérica\ndef test(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    y_pred, y_true= [], []\n\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n\n            running_loss += loss.item()\n            predicted = outputs.argmax(dim = 1)\n            \n            y_true.extend(labels.cpu().tolist())\n            y_pred.extend(predicted.cpu().tolist())\n            \n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    test_loss = running_loss / len(list(dataloader.dataset))\n    test_accuracy = accuracy = accuracy_score(y_true, y_pred)\n    precision, recall, test_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro',zero_division=0)\n    \n    print(f\"Test Loss: {test_loss:.6f} | Test Accuracy: {(test_accuracy * 100):.2f}% | Test F1-Score: {test_f1:.6f}\")\n    return test_loss, test_accuracy, test_f1\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:35.545919Z","iopub.execute_input":"2023-06-21T20:51:35.546275Z","iopub.status.idle":"2023-06-21T20:51:35.557922Z","shell.execute_reply.started":"2023-06-21T20:51:35.546245Z","shell.execute_reply":"2023-06-21T20:51:35.557060Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Função genérica para treinar, testar\ndef train_model(model_type, exp,model, train_dataloader, test_dataloader, criterion, optimizer, scheduler, device, num_epochs, ft, num):\n    model=model.to(device)\n    train_losses = []\n    train_accuracies = []\n    test_losses = []\n    test_accuracies = []\n\n    for epoch in range(num_epochs):\n        print('----------------------------------------------------------------------------')\n        train_loss, train_accuracy, train_f1 = train(model, train_dataloader, criterion, optimizer, scheduler, device, ft, epoch, exp, model_type)\n        test_loss, test_accuracy,test_f1 = test(model, test_dataloader, criterion, device)\n        val=str(num)+str(epoch+1)\n        df.loc[val]=[model_type, exp, epoch+1, train_accuracy, train_loss, train_f1, test_accuracy, test_loss, test_f1]\n        print('\\n')\n        \n        \n        \n    return train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:35.561078Z","iopub.execute_input":"2023-06-21T20:51:35.561703Z","iopub.status.idle":"2023-06-21T20:51:35.570223Z","shell.execute_reply.started":"2023-06-21T20:51:35.561676Z","shell.execute_reply":"2023-06-21T20:51:35.569479Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## **3.3. Protocolo Experimental**","metadata":{}},{"cell_type":"markdown","source":"Aplicando protocolo experimental para os cenários resultantes das permutações dos Aumentos de Dados (AutoAugment e RandAugment) e Fine-Tuning\n1. Sem Fine-Tuning\n2. Com Fine-Tuning\n3. Sem Fine Tuning e com AutoAugment\n4. Com Fine Tuning e com AutoAugment\n5. Sem Fine Tuning e com RandAugment\n6. Com Fine Tuning e com RandAugment\n7. Sem Fine Tuning e com AutoAugment e RandAugment\n8. Com Fine Tuning e com AutoAugment e RandAugment","metadata":{}},{"cell_type":"code","source":"def run_scenario(model_type, scenario, data_fraction, num_epochs=10, batch_size=32, learning_rate=0.001):\n    num_classes = 2  \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    num_train_data = int((100000) * data_fraction)\n    num_test_data = int((20000) * data_fraction)\n    \n    train_indices = random.sample(range(100000), num_train_data)\n    test_indices = random.sample(range(20000), num_test_data)\n    \n    print(f'Número de objetos de treino: {num_train_data}')\n    print(f'Número de objetos de teste: {num_test_data}')\n    print(\"============================================================================\")\n    \n    if scenario == 1:\n        \n        train_dataloader, test_dataloader= full_data_transform(model_type, data_fraction, batch_size)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n            num=1\n\n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n            num=9\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n        \n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 1 - ConvNeXt (Sem Fine-Tuning)\")\n        elif model_type == 'vit':\n            print(\"Experimento 1 - ViT (Sem Fine-Tuning)\")\n        \n        train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1 = train_model(model_type,1, model, train_dataloader, test_dataloader,\n                                                                                    criterion, optimizer, scheduler, device, 1, False, num)\n    elif scenario == 2:\n        \n        train_dataloader, test_dataloader= full_data_transform(model_type, data_fraction, batch_size)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n            num=2\n\n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n            num=10\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n             print(\"Experimento 2 - ConvNeXt (Com Fine-Tuning)\")\n        elif model_type == 'vit':\n            print(\"Experimento 2 - ViT (Com Fine-Tuning)\")\n        \n        train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1 = train_model(model_type,2, model, train_dataloader, test_dataloader,\n                                                                                    criterion, optimizer, scheduler, device, num_epochs, True, num)\n    elif scenario == 3:\n        \n        augmented_train_dataloader = AutoAugment_transform(model_type, train_indices, batch_size)\n        test_dataloader=ft_data_transform(model_type, data_fraction, batch_size)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n            num=3\n\n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n            num=11\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 3 - ConvNeXt (Sem Fine-Tuning e com AutoAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 3 - ViT (Sem Fine-Tuning e com AutoAugment)\")\n        \n        \n        train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1 = train_model(model_type,3, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, 1, False, num)\n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n            num=4\n            \n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n            num=12\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 4 - ConvNeXt (Com Fine-Tuning e com AutoAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 4 - ViT (Com Fine-Tuning e com AutoAugment)\")\n        \n        train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1 = train_model(model_type,4, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, num_epochs, True, num)\n    \n    elif scenario == 4:\n        augmented_train_dataloader = RandAugment_transform(model_type, train_indices, batch_size)\n        test_dataloader=ft_data_transform(model_type, data_fraction, batch_size)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n            num=5\n            \n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n            num=13\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n  \n        if model_type == 'convnext':\n            print(\"Experimento 5 - ConvNeXt (Sem Fine-Tuning e com RandAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 5 - ViT (Sem Fine-Tuning e com RandAugment)\")    \n        \n        train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1 = train_model(model_type,5, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, 1, False, num)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n            num=6\n            \n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n            num=14\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 6 - ConvNeXt (Com Fine-Tuning e com RandAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 6 - ViT (Com Fine-Tuning e com RandAugment)\")\n        \n        \n        train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1 = train_model(model_type,6, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, num_epochs, True, num) \n\n    elif scenario == 5:\n        augmented_train_dataloader = Auto_RandAugment_transform(model_type, train_indices, batch_size)\n        test_dataloader=ft_data_transform(model_type, data_fraction, batch_size)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n            num=7\n            \n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n            num=15\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 7 - ConvNeXt (Sem Fine-Tuning e com RandAugment e AutoAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 7 - ViT (Sem Fine-Tuning e com RandAugment e AutoAugment)\")\n            \n        train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1 = train_model(model_type,7, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, 1, False, num)\n      \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n            num=8\n            \n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n            num=16\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 8 - ConvNeXt (Com Fine-Tuning e com RandAugment e AutoAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 8 - ViT (Com Fine-Tuning e com RandAugment e AutoAugment)\")\n\n        train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1 = train_model(model_type,8, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, num_epochs, True, num)\n    else:\n        raise ValueError(\"O parâmetro 'scenario' deve ser um número entre 1 e 5.\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:35.571639Z","iopub.execute_input":"2023-06-21T20:51:35.572254Z","iopub.status.idle":"2023-06-21T20:51:35.614161Z","shell.execute_reply.started":"2023-06-21T20:51:35.572205Z","shell.execute_reply":"2023-06-21T20:51:35.613252Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## **3.4. Avaliação de Desempenho**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_experiment_graphs(df, experiment_number):\n    experiment_df = df[df['Experimento'] == experiment_number]\n\n    # Plot epoch x train F1\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Train F1'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Train F1')\n    plt.title(f'Experimento {experiment_number} - Train F1')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x train accuracy\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Train ACC'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Acurácia de Treino')\n    plt.title(f'Experimento {experiment_number} - Acurácia de Treino')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x train loss\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Train Loss'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Perda de Treino')\n    plt.title(f'Experimento {experiment_number} - Perda de Treino')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x test F1\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Test F1'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Test F1')\n    plt.title(f'Experimento {experiment_number} - Test F1')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x test accuracy\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Test ACC'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Acurácia de Teste')\n    plt.title(f'Experimento {experiment_number} - Acurácia de Teste')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x test loss\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Test Loss'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Perda de Teste')\n    plt.title(f'Experimento {experiment_number} - Perda de Teste')\n    plt.tight_layout()\n    plt.show()\n\ndef plot_general_graphs(df):\n    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n\n    # Plot epoch x train F1\n    ax1 = axes[0, 0]\n    for experiment_number in df['Experimento'].unique():\n        experiment_df = df[df['Experimento'] == experiment_number]\n        ax1.plot(experiment_df['Epoch'], experiment_df['Train F1'], marker='o', label=f'Experimento {experiment_number}')\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Train F1')\n    ax1.set_title('Geral - Train F1')\n    ax1.legend()\n\n    # Plot epoch x train loss\n    ax2 = axes[0, 1]\n    for experiment_number in df['Experimento'].unique():\n        experiment_df = df[df['Experimento'] == experiment_number]\n        ax2.plot(experiment_df['Epoch'], experiment_df['Train Loss'], marker='o', label=f'Experimento {experiment_number}')\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Perda de Treino')\n    ax2.set_title('Geral - Perda de Treino')\n    ax2.legend()\n\n    # Plot epoch x test F1\n    ax3 = axes[1, 0]\n    for experiment_number in df['Experimento'].unique():\n        experiment_df = df[df['Experimento'] == experiment_number]\n        ax3.plot(experiment_df['Epoch'], experiment_df['Test F1'], marker='o', label=f'Experimento {experiment_number}')\n    ax3.set_xlabel('Epoch')\n    ax3.set_ylabel('Test F1')\n    ax3.set_title('Geral - Test F1')\n    ax3.legend()\n\n    # Plot epoch x test loss\n    ax4 = axes[1, 1]\n    for experiment_number in df['Experimento'].unique():\n        experiment_df = df[df['Experimento'] == experiment_number]\n        ax4.plot(experiment_df['Epoch'], experiment_df['Test Loss'], marker='o', label=f'Experimento {experiment_number}')\n    ax4.set_xlabel('Epoch')\n    ax4.set_ylabel('Perda de Teste')\n    ax4.set_title('Geral - Perda de Teste')\n    ax4.legend()\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:35.616037Z","iopub.execute_input":"2023-06-21T20:51:35.616573Z","iopub.status.idle":"2023-06-21T20:51:35.637234Z","shell.execute_reply.started":"2023-06-21T20:51:35.616542Z","shell.execute_reply":"2023-06-21T20:51:35.636298Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\nrun_scenario('convnext',1,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:35.640310Z","iopub.execute_input":"2023-06-21T20:51:35.640615Z","iopub.status.idle":"2023-06-21T20:51:38.846920Z","shell.execute_reply.started":"2023-06-21T20:51:35.640584Z","shell.execute_reply":"2023-06-21T20:51:38.844340Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Número de objetos de treino: 10000\nNúmero de objetos de teste: 2000\n============================================================================\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_scenario\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconvnext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[16], line 17\u001b[0m, in \u001b[0;36mrun_scenario\u001b[0;34m(model_type, scenario, data_fraction, num_epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m============================================================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scenario \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 17\u001b[0m     train_dataloader, test_dataloader\u001b[38;5;241m=\u001b[39m \u001b[43mfull_data_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_fraction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Selecionar o modelo\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconvnext\u001b[39m\u001b[38;5;124m'\u001b[39m:\n","Cell \u001b[0;32mIn[9], line 15\u001b[0m, in \u001b[0;36mfull_data_transform\u001b[0;34m(model_type, data_fraction, batch_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m     transform \u001b[38;5;241m=\u001b[39m ViT_B_16_Weights\u001b[38;5;241m.\u001b[39mIMAGENET1K_V1\u001b[38;5;241m.\u001b[39mtransforms()\n\u001b[1;32m     14\u001b[0m local_arquivos\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 15\u001b[0m full_train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_arquivos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m full_test_dataset \u001b[38;5;241m=\u001b[39m ImageFolder(local_arquivos \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/test\u001b[39m\u001b[38;5;124m\"\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Determinar o número de objetos a serem selecionados\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/datasets/folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    303\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    308\u001b[0m ):\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/datasets/folder.py:145\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m    144\u001b[0m classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_classes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot)\n\u001b[0;32m--> 145\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextensions \u001b[38;5;241m=\u001b[39m extensions\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/datasets/folder.py:189\u001b[0m, in \u001b[0;36mDatasetFolder.make_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_to_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# prevent potential bug since make_dataset() would use the class_to_idx logic of the\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# find_classes() function, instead of using that of the find_classes() method, which\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;66;03m# is potentially overridden and thus could have a different logic.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe class_to_idx parameter cannot be None.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/datasets/folder.py:87\u001b[0m, in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(target_dir):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m root, _, fnames \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwalk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollowlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(fnames):\n\u001b[1;32m     89\u001b[0m         path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, fname)\n","File \u001b[0;32m/opt/conda/lib/python3.10/os.py:368\u001b[0m, in \u001b[0;36m_walk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m         entry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscandir_it\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.848419Z","iopub.status.idle":"2023-06-21T20:51:38.848879Z","shell.execute_reply.started":"2023-06-21T20:51:38.848642Z","shell.execute_reply":"2023-06-21T20:51:38.848665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('convnext',2,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.850739Z","iopub.status.idle":"2023-06-21T20:51:38.851185Z","shell.execute_reply.started":"2023-06-21T20:51:38.850960Z","shell.execute_reply":"2023-06-21T20:51:38.850981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.852901Z","iopub.status.idle":"2023-06-21T20:51:38.853351Z","shell.execute_reply.started":"2023-06-21T20:51:38.853112Z","shell.execute_reply":"2023-06-21T20:51:38.853132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('convnext',3,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:42.690977Z","iopub.execute_input":"2023-06-21T20:51:42.691775Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Número de objetos de treino: 10000\nNúmero de objetos de teste: 2000\n============================================================================\nExperimento 3 - ConvNeXt (Sem Fine-Tuning e com AutoAugment)\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 1]: 100%|██████████| 625/625 [02:04<00:00,  5.03it/s, loss=0.703]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.044420 | Train Accuracy: 49.45% | Train F1-Score: 0.456475\nTest Loss: 0.089519 | Test Accuracy: 49.15% | Test F1-Score: 0.452624\n\n\nExperimento 4 - ConvNeXt (Com Fine-Tuning e com AutoAugment)\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 1]: 100%|██████████| 625/625 [02:41<00:00,  3.87it/s, loss=0.063]  \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.012796 | Train Accuracy: 90.61% | Train F1-Score: 0.906089\nTest Loss: 0.003157 | Test Accuracy: 99.25% | Test F1-Score: 0.992500\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 2]: 100%|██████████| 625/625 [02:40<00:00,  3.88it/s, loss=0.0513]  \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.002713 | Train Accuracy: 98.50% | Train F1-Score: 0.984997\nTest Loss: 0.001385 | Test Accuracy: 99.65% | Test F1-Score: 0.996500\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 3]: 100%|██████████| 625/625 [02:40<00:00,  3.89it/s, loss=0.000872]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.001261 | Train Accuracy: 99.33% | Train F1-Score: 0.993298\nTest Loss: 0.000513 | Test Accuracy: 99.85% | Test F1-Score: 0.998500\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 4]: 100%|██████████| 625/625 [02:40<00:00,  3.89it/s, loss=0.0065]  \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000702 | Train Accuracy: 99.64% | Train F1-Score: 0.996399\nTest Loss: 0.000432 | Test Accuracy: 99.90% | Test F1-Score: 0.999000\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 5]: 100%|██████████| 625/625 [02:39<00:00,  3.91it/s, loss=0.000567]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000534 | Train Accuracy: 99.69% | Train F1-Score: 0.996899\nTest Loss: 0.000239 | Test Accuracy: 99.95% | Test F1-Score: 0.999500\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 6]: 100%|██████████| 625/625 [02:41<00:00,  3.86it/s, loss=0.000245]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000658 | Train Accuracy: 99.59% | Train F1-Score: 0.995899\nTest Loss: 0.000283 | Test Accuracy: 99.90% | Test F1-Score: 0.999000\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 7]: 100%|██████████| 625/625 [02:41<00:00,  3.87it/s, loss=0.0038]  \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.000580 | Train Accuracy: 99.71% | Train F1-Score: 0.997099\nTest Loss: 0.000253 | Test Accuracy: 99.95% | Test F1-Score: 0.999500\n\n\n----------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"[Epoch 8]:  65%|██████▌   | 408/625 [01:46<00:55,  3.89it/s, loss=0.00839] ","output_type":"stream"}]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.859012Z","iopub.status.idle":"2023-06-21T20:51:38.859783Z","shell.execute_reply.started":"2023-06-21T20:51:38.859554Z","shell.execute_reply":"2023-06-21T20:51:38.859575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('convnext',4,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.865422Z","iopub.status.idle":"2023-06-21T20:51:38.866159Z","shell.execute_reply.started":"2023-06-21T20:51:38.865925Z","shell.execute_reply":"2023-06-21T20:51:38.865947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.867511Z","iopub.status.idle":"2023-06-21T20:51:38.868231Z","shell.execute_reply.started":"2023-06-21T20:51:38.867998Z","shell.execute_reply":"2023-06-21T20:51:38.868019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('convnext',5,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.869574Z","iopub.status.idle":"2023-06-21T20:51:38.870320Z","shell.execute_reply.started":"2023-06-21T20:51:38.870088Z","shell.execute_reply":"2023-06-21T20:51:38.870110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.871669Z","iopub.status.idle":"2023-06-21T20:51:38.872426Z","shell.execute_reply.started":"2023-06-21T20:51:38.872173Z","shell.execute_reply":"2023-06-21T20:51:38.872195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',1,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.873748Z","iopub.status.idle":"2023-06-21T20:51:38.874488Z","shell.execute_reply.started":"2023-06-21T20:51:38.874237Z","shell.execute_reply":"2023-06-21T20:51:38.874258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.875877Z","iopub.status.idle":"2023-06-21T20:51:38.876615Z","shell.execute_reply.started":"2023-06-21T20:51:38.876384Z","shell.execute_reply":"2023-06-21T20:51:38.876406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',2,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.877950Z","iopub.status.idle":"2023-06-21T20:51:38.878725Z","shell.execute_reply.started":"2023-06-21T20:51:38.878477Z","shell.execute_reply":"2023-06-21T20:51:38.878500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.880127Z","iopub.status.idle":"2023-06-21T20:51:38.880887Z","shell.execute_reply.started":"2023-06-21T20:51:38.880647Z","shell.execute_reply":"2023-06-21T20:51:38.880668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',3,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.882416Z","iopub.status.idle":"2023-06-21T20:51:38.883205Z","shell.execute_reply.started":"2023-06-21T20:51:38.882972Z","shell.execute_reply":"2023-06-21T20:51:38.882994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.884569Z","iopub.status.idle":"2023-06-21T20:51:38.885291Z","shell.execute_reply.started":"2023-06-21T20:51:38.885059Z","shell.execute_reply":"2023-06-21T20:51:38.885081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',4,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.886641Z","iopub.status.idle":"2023-06-21T20:51:38.887397Z","shell.execute_reply.started":"2023-06-21T20:51:38.887145Z","shell.execute_reply":"2023-06-21T20:51:38.887167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.888874Z","iopub.status.idle":"2023-06-21T20:51:38.889591Z","shell.execute_reply.started":"2023-06-21T20:51:38.889362Z","shell.execute_reply":"2023-06-21T20:51:38.889383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',5,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.890928Z","iopub.status.idle":"2023-06-21T20:51:38.891669Z","shell.execute_reply.started":"2023-06-21T20:51:38.891427Z","shell.execute_reply":"2023-06-21T20:51:38.891449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:51:38.893529Z","iopub.status.idle":"2023-06-21T20:51:38.894242Z","shell.execute_reply.started":"2023-06-21T20:51:38.894060Z","shell.execute_reply":"2023-06-21T20:51:38.894078Z"},"trusted":true},"execution_count":null,"outputs":[]}]}