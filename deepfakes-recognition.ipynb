{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Algoritmo Para Detecção de Imagens de Faces DeepFakes Por Meio de Aprendizado de Máquina**\n## Universidade Federal de São Paulo - UNIFESP\n\n### Disciplina: Inteligência Artificial\n### Professor: Fábio Faria\n### Integrantes:\n###  -  Marco Antonio Coral dos Santos\n###  -  Raphael Damasceno Rocha de Moraes","metadata":{}},{"cell_type":"markdown","source":"# **1. Introdução**","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-21T21:08:07.371637Z","iopub.execute_input":"2023-06-21T21:08:07.372181Z","iopub.status.idle":"2023-06-21T21:08:07.390525Z","shell.execute_reply.started":"2023-06-21T21:08:07.372141Z","shell.execute_reply":"2023-06-21T21:08:07.388167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport random\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport seaborn as sb\nimport torch \nfrom torchvision import models\nfrom torch import nn\nfrom torch import optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.models.vision_transformer import vit_b_16, ViT_B_16_Weights\nfrom torchvision.utils import make_grid\nfrom torch.autograd import Variable\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score, accuracy_score, precision_recall_fscore_support\nimport shutil\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ncode_dir = \"/kaggle/working/code\"\nmodel_dir = \"/kaggle/working/model\"\noutput_dir = \"/kaggle/working/output\"\n\nif not os.path.exists(code_dir):\n    os.mkdir(code_dir)\n\nif not os.path.exists(model_dir):\n    os.mkdir(model_dir)\n\nif not os.path.exists(output_dir):\n    os.mkdir(output_dir)\n    \nshutil.copyfile(src=\"/kaggle/input/modelos/convnext.py\", \n                dst=\"/kaggle/working/code/convnext.py\")\nshutil.copyfile(src=\"/kaggle/input/modelos/convnext_tiny_1k_224_ema.pth\", \n                dst=\"/kaggle/working/model/convnext_tiny_1k_224_ema.pth\")\nshutil.copyfile(src=\"/kaggle/input/modelos/vit_b_16-c867db91.pth\", \n                dst=\"/kaggle/working/model/vit_b_16-c867db91.pth\")\n\nos.chdir(\"/kaggle/working/code\")\n\n\nfrom convnext import ConvNeXt\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:08:10.988369Z","iopub.execute_input":"2023-06-21T21:08:10.988837Z","iopub.status.idle":"2023-06-21T21:08:20.826466Z","shell.execute_reply.started":"2023-06-21T21:08:10.988801Z","shell.execute_reply":"2023-06-21T21:08:20.825570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **2. Banco de Dados**","metadata":{}},{"cell_type":"code","source":"local_arquivos='/kaggle/input/140k-real-and-fake-faces'\ntreino = pd.read_csv(local_arquivos + \"/train.csv\")\nteste = pd.read_csv(local_arquivos + \"/test.csv\")\nprint(teste.shape)\nprint(treino.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:08:27.392441Z","iopub.execute_input":"2023-06-21T21:08:27.392823Z","iopub.status.idle":"2023-06-21T21:08:27.932294Z","shell.execute_reply.started":"2023-06-21T21:08:27.392793Z","shell.execute_reply":"2023-06-21T21:08:27.931366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **2.1. Arquiteturas de Rede**","metadata":{}},{"cell_type":"code","source":"#Instanciando o modelo ConvNeXt \ndef ConvNeXt_model():\n    model_conv=ConvNeXt()\n    state_dict = torch.load('/kaggle/working/model/convnext_tiny_1k_224_ema.pth')\n    model_conv.load_state_dict(state_dict[\"model\"])\n    \n    return model_conv\n\ndef ViT_model():\n    model_vit=vit_b_16(pretrained=True)\n    return model_vit\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:08:32.401900Z","iopub.execute_input":"2023-06-21T21:08:32.402478Z","iopub.status.idle":"2023-06-21T21:08:32.408524Z","shell.execute_reply.started":"2023-06-21T21:08:32.402446Z","shell.execute_reply":"2023-06-21T21:08:32.407236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:08:36.471065Z","iopub.execute_input":"2023-06-21T21:08:36.471430Z","iopub.status.idle":"2023-06-21T21:08:36.506143Z","shell.execute_reply.started":"2023-06-21T21:08:36.471403Z","shell.execute_reply":"2023-06-21T21:08:36.504696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"  criterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:08:38.398716Z","iopub.execute_input":"2023-06-21T21:08:38.399066Z","iopub.status.idle":"2023-06-21T21:08:38.403438Z","shell.execute_reply.started":"2023-06-21T21:08:38.399040Z","shell.execute_reply":"2023-06-21T21:08:38.402477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:08:43.155480Z","iopub.execute_input":"2023-06-21T21:08:43.156182Z","iopub.status.idle":"2023-06-21T21:08:43.161759Z","shell.execute_reply.started":"2023-06-21T21:08:43.156117Z","shell.execute_reply":"2023-06-21T21:08:43.160501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_acc, teste_acc, train_loss, teste_loss = [], [], [], []\ntrain_precision, teste_precision, train_recall, teste_recall = [], [], [], []\ntrain_f1, teste_f1 = [], []\ndf = pd.DataFrame(columns=['Modelo','Experimento','Epoch', 'Train ACC', 'Train Loss', 'Train F1', 'Test ACC', 'Test Loss', 'Test F1'])","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:08:45.951307Z","iopub.execute_input":"2023-06-21T21:08:45.951652Z","iopub.status.idle":"2023-06-21T21:08:45.961393Z","shell.execute_reply.started":"2023-06-21T21:08:45.951623Z","shell.execute_reply":"2023-06-21T21:08:45.960196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **3. Metodologia**","metadata":{}},{"cell_type":"markdown","source":"## **3.1. Aumento de Dados**","metadata":{}},{"cell_type":"markdown","source":"### **3.1.1. Processamento das Imagens**","metadata":{}},{"cell_type":"code","source":"def full_data_transform(model_type, data_fraction, batch_size):\n    # Transformações de dados\n    if model_type== 'convnext':\n        transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    elif model_type == 'vit':\n        transform = ViT_B_16_Weights.IMAGENET1K_V1.transforms()\n            \n            \n    local_arquivos='/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n    full_train_dataset = ImageFolder(local_arquivos + \"/train\", transform=transform)\n    full_test_dataset = ImageFolder(local_arquivos + \"/test\", transform=transform)\n            \n    # Determinar o número de objetos a serem selecionados\n    num_train_data = int(len(full_train_dataset) * data_fraction)\n    num_test_data = int(len(full_test_dataset) * data_fraction)\n    \n    \n\n    # Selecionar aleatoriamente os objetos para os conjuntos de dados\n    train_indices = random.sample(range(len(full_train_dataset)), num_train_data)\n    test_indices = random.sample(range(len(full_test_dataset)), num_test_data)\n\n    # Criar os datasets com a seleção aleatória de objetos\n    train_dataset = torch.utils.data.Subset(full_train_dataset, train_indices)\n    test_dataset = torch.utils.data.Subset(full_test_dataset, test_indices)\n    \n    # Criação dos dataloaders\n    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    test_dataloader = DataLoader(test_dataset, batch_size=int(batch_size/2), shuffle=False)\n        \n        \n    return train_dataloader, test_dataloader\n\ndef ft_data_transform(model_type, data_fraction, batch_size):\n    # Transformações de dados\n    if model_type== 'convnext':\n        transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n        \n    \n    elif model_type == 'vit':\n        transform = ViT_B_16_Weights.IMAGENET1K_V1.transforms()\n\n    local_arquivos='/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n    full_test_dataset = ImageFolder(local_arquivos + \"/test\", transform=transform)\n            \n    # Determinar o número de objetos a serem selecionados\n    num_test_data = int(len(full_test_dataset) * data_fraction)\n    \n\n    # Selecionar aleatoriamente os objetos para os conjuntos de dados\n    test_indices = random.sample(range(len(full_test_dataset)), num_test_data)\n\n    # Criar os datasets com a seleção aleatória de objetos\n    test_dataset = torch.utils.data.Subset(full_test_dataset, test_indices)\n    \n    # Criação dos dataloaders\n    test_dataloader = DataLoader(test_dataset, batch_size=int(batch_size/2), shuffle=False)\n\n    return test_dataloader","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:08:50.204606Z","iopub.execute_input":"2023-06-21T21:08:50.204983Z","iopub.status.idle":"2023-06-21T21:08:50.220986Z","shell.execute_reply.started":"2023-06-21T21:08:50.204955Z","shell.execute_reply":"2023-06-21T21:08:50.220012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **3.1.2. AutoAugment**","metadata":{}},{"cell_type":"code","source":"def AutoAugment_transform(model_type, train_indices, batch_size):\n    if model_type== 'convnext':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.AutoAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n        \n    elif model_type == 'vit':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(224, interpolation=Image.BILINEAR),\n            transforms.CenterCrop(224),\n            transforms.AutoAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n        ])\n    local_arquivos='/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n    augmented_train_dataset = ImageFolder(local_arquivos + \"/train\", transform=augmentation_transforms)\n    augmented_train_dataset = torch.utils.data.Subset(augmented_train_dataset, train_indices)\n    augmented_train_dataloader = DataLoader(augmented_train_dataset, batch_size=batch_size, shuffle=True)\n    \n    return augmented_train_dataloader\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:08:55.014812Z","iopub.execute_input":"2023-06-21T21:08:55.015157Z","iopub.status.idle":"2023-06-21T21:08:55.024025Z","shell.execute_reply.started":"2023-06-21T21:08:55.015131Z","shell.execute_reply":"2023-06-21T21:08:55.022831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **3.1.3. RandAugment**","metadata":{}},{"cell_type":"code","source":"def RandAugment_transform(model_type, train_indices, batch_size):\n    if model_type== 'convnext':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.RandAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    \n    elif model_type == 'vit':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(224, interpolation=Image.BILINEAR),\n            transforms.CenterCrop(224),\n            transforms.RandAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n        ])\n        \n    local_arquivos='/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n    augmented_train_dataset = ImageFolder(local_arquivos + \"/train\", transform=augmentation_transforms)\n    augmented_train_dataset = torch.utils.data.Subset(augmented_train_dataset, train_indices)\n    augmented_train_dataloader = DataLoader(augmented_train_dataset, batch_size=batch_size, shuffle=True)\n    \n    return augmented_train_dataloader\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:08:59.021536Z","iopub.execute_input":"2023-06-21T21:08:59.022215Z","iopub.status.idle":"2023-06-21T21:08:59.030275Z","shell.execute_reply.started":"2023-06-21T21:08:59.022183Z","shell.execute_reply":"2023-06-21T21:08:59.029300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **3.1.4. Auto+Rand Augment**","metadata":{}},{"cell_type":"code","source":"def Auto_RandAugment_transform(model_type, train_indices, batch_size):\n    if model_type== 'convnext':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(256),\n            transforms.AutoAugment(),\n            transforms.RandAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    \n    elif model_type == 'vit':\n        augmentation_transforms = transforms.Compose([\n            transforms.Resize(224, interpolation=Image.BILINEAR),\n            transforms.CenterCrop(224),\n            transforms.AutoAugment(),\n            transforms.RandAugment(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n        ])\n        \n    local_arquivos='/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n    augmented_train_dataset = ImageFolder(local_arquivos + \"/train\", transform=augmentation_transforms)\n    augmented_train_dataset = torch.utils.data.Subset(augmented_train_dataset, train_indices)\n    augmented_train_dataloader = DataLoader(augmented_train_dataset, batch_size=batch_size, shuffle=True)\n    \n    return augmented_train_dataloader","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:09:02.284545Z","iopub.execute_input":"2023-06-21T21:09:02.285252Z","iopub.status.idle":"2023-06-21T21:09:02.293908Z","shell.execute_reply.started":"2023-06-21T21:09:02.285218Z","shell.execute_reply":"2023-06-21T21:09:02.292724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **3.2. Treinamento e Teste**","metadata":{}},{"cell_type":"code","source":" # Função de treino genérica\ndef train(model, dataloader, criterion, optimizer, scheduler, device, ft, epoch, exp, model_type):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    y_true,y_pred=[], []\n    \n    loop = tqdm(enumerate(dataloader), total=len(dataloader))\n    for batch_idx, (images, labels) in loop:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        if ft==False:\n            for param in model.parameters():\n                param.requires_grad=False\n                \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            optimizer.step()\n            \n            for param in model.parameters():\n                param.requires_grad=True\n        else:    \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n                \n        running_loss += loss.item()\n        predicted = outputs.argmax(dim = 1)\n    \n        y_true.extend(labels.cpu().tolist())\n        y_pred.extend(predicted.cpu().tolist())\n\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n        \n        loop.set_description(f\"[Epoch {(epoch+1)}]\")\n        loop.set_postfix(loss=loss.item())\n        \n    if scheduler:\n        scheduler.step()\n        \n    train_loss = running_loss / len(dataloader.dataset)  \n    accuracy = accuracy_score(y_true, y_pred)\n    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro',zero_division=0)\n\n    print(f\"Train Loss: {train_loss:.6f} | Train Accuracy: {(accuracy * 100):.2f}% | Train F1-Score: {f1:.6f}\")\n    \n    model_name= f'model_{model_type}_params_exp_{exp}.pth'\n    torch.save(model.state_dict(), os.path.join('/kaggle/working/model', model_name))\n   \n    return train_loss, accuracy, f1","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:09:05.892070Z","iopub.execute_input":"2023-06-21T21:09:05.892427Z","iopub.status.idle":"2023-06-21T21:09:05.904306Z","shell.execute_reply.started":"2023-06-21T21:09:05.892398Z","shell.execute_reply":"2023-06-21T21:09:05.903410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Função de teste genérica\ndef test(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    y_pred, y_true= [], []\n\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n\n            running_loss += loss.item()\n            predicted = outputs.argmax(dim = 1)\n            \n            y_true.extend(labels.cpu().tolist())\n            y_pred.extend(predicted.cpu().tolist())\n            \n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    test_loss = running_loss / len(list(dataloader.dataset))\n    test_accuracy = accuracy = accuracy_score(y_true, y_pred)\n    precision, recall, test_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro',zero_division=0)\n    \n    print(f\"Test Loss: {test_loss:.6f} | Test Accuracy: {(test_accuracy * 100):.2f}% | Test F1-Score: {test_f1:.6f}\")\n    return test_loss, test_accuracy, test_f1\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:09:09.766341Z","iopub.execute_input":"2023-06-21T21:09:09.767184Z","iopub.status.idle":"2023-06-21T21:09:09.776204Z","shell.execute_reply.started":"2023-06-21T21:09:09.767150Z","shell.execute_reply":"2023-06-21T21:09:09.775109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Função genérica para treinar, testar\ndef train_model(model_type, exp,model, train_dataloader, test_dataloader, criterion, optimizer, scheduler, device, num_epochs, ft, num):\n    model=model.to(device)\n    train_losses = []\n    train_accuracies = []\n    test_losses = []\n    test_accuracies = []\n\n    for epoch in range(num_epochs):\n        print('----------------------------------------------------------------------------')\n        train_loss, train_accuracy, train_f1 = train(model, train_dataloader, criterion, optimizer, scheduler, device, ft, epoch, exp, model_type)\n        test_loss, test_accuracy,test_f1 = test(model, test_dataloader, criterion, device)\n        val=str(num)+str(epoch+1)\n        df.loc[val]=[model_type, exp, epoch+1, train_accuracy, train_loss, train_f1, test_accuracy, test_loss, test_f1]\n        df.to_csv('metricas.csv', index = False)\n        print('\\n')\n        \n        \n        \n    return train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:09:13.249498Z","iopub.execute_input":"2023-06-21T21:09:13.249895Z","iopub.status.idle":"2023-06-21T21:09:13.258605Z","shell.execute_reply.started":"2023-06-21T21:09:13.249864Z","shell.execute_reply":"2023-06-21T21:09:13.257625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **3.3. Protocolo Experimental**","metadata":{}},{"cell_type":"markdown","source":"Aplicando protocolo experimental para os cenários resultantes das permutações dos Aumentos de Dados (AutoAugment e RandAugment) e Fine-Tuning\n1. Sem Fine-Tuning\n2. Com Fine-Tuning\n3. Sem Fine Tuning e com AutoAugment\n4. Com Fine Tuning e com AutoAugment\n5. Sem Fine Tuning e com RandAugment\n6. Com Fine Tuning e com RandAugment\n7. Sem Fine Tuning e com AutoAugment e RandAugment\n8. Com Fine Tuning e com AutoAugment e RandAugment","metadata":{}},{"cell_type":"code","source":"def run_scenario(model_type, scenario, data_fraction, num_epochs=10, batch_size=32, learning_rate=0.001):\n    num_classes = 2  \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    num_train_data = int((100000) * data_fraction)\n    num_test_data = int((20000) * data_fraction)\n    \n    train_indices = random.sample(range(100000), num_train_data)\n    test_indices = random.sample(range(20000), num_test_data)\n    \n    print(f'Número de objetos de treino: {num_train_data}')\n    print(f'Número de objetos de teste: {num_test_data}')\n    print(\"============================================================================\")\n    \n    if scenario == 1:\n        \n        train_dataloader, test_dataloader= full_data_transform(model_type, data_fraction, batch_size)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n            num=1\n\n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n            num=9\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n        \n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 1 - ConvNeXt (Sem Fine-Tuning)\")\n        elif model_type == 'vit':\n            print(\"Experimento 1 - ViT (Sem Fine-Tuning)\")\n        \n        train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1 = train_model(model_type,1, model, train_dataloader, test_dataloader,\n                                                                                    criterion, optimizer, scheduler, device, 1, False, num)\n    elif scenario == 2:\n        \n        train_dataloader, test_dataloader= full_data_transform(model_type, data_fraction, batch_size)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n            num=2\n\n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n            num=10\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n             print(\"Experimento 2 - ConvNeXt (Com Fine-Tuning)\")\n        elif model_type == 'vit':\n            print(\"Experimento 2 - ViT (Com Fine-Tuning)\")\n        \n        train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1 = train_model(model_type,2, model, train_dataloader, test_dataloader,\n                                                                                    criterion, optimizer, scheduler, device, num_epochs, True, num)\n    elif scenario == 3:\n        \n        augmented_train_dataloader = AutoAugment_transform(model_type, train_indices, batch_size)\n        test_dataloader=ft_data_transform(model_type, data_fraction, batch_size)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n            num=3\n\n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n            num=11\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 3 - ConvNeXt (Sem Fine-Tuning e com AutoAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 3 - ViT (Sem Fine-Tuning e com AutoAugment)\")\n        \n        \n        train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1 = train_model(model_type,3, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, 1, False, num)\n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n            num=4\n            \n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n            num=12\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 4 - ConvNeXt (Com Fine-Tuning e com AutoAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 4 - ViT (Com Fine-Tuning e com AutoAugment)\")\n        \n        train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1 = train_model(model_type,4, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, num_epochs, True, num)\n    \n    elif scenario == 4:\n        augmented_train_dataloader = RandAugment_transform(model_type, train_indices, batch_size)\n        test_dataloader=ft_data_transform(model_type, data_fraction, batch_size)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n            num=5\n            \n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n            num=13\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n  \n        if model_type == 'convnext':\n            print(\"Experimento 5 - ConvNeXt (Sem Fine-Tuning e com RandAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 5 - ViT (Sem Fine-Tuning e com RandAugment)\")    \n        \n        train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1 = train_model(model_type,5, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, 1, False, num)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n            num=6\n            \n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n            num=14\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 6 - ConvNeXt (Com Fine-Tuning e com RandAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 6 - ViT (Com Fine-Tuning e com RandAugment)\")\n        \n        \n        train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1 = train_model(model_type,6, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, num_epochs, True, num) \n\n    elif scenario == 5:\n        augmented_train_dataloader = Auto_RandAugment_transform(model_type, train_indices, batch_size)\n        test_dataloader=ft_data_transform(model_type, data_fraction, batch_size)\n        \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n            num=7\n            \n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n            num=15\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 7 - ConvNeXt (Sem Fine-Tuning e com RandAugment e AutoAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 7 - ViT (Sem Fine-Tuning e com RandAugment e AutoAugment)\")\n            \n        train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1 = train_model(model_type,7, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, 1, False, num)\n      \n        # Selecionar o modelo\n        if model_type == 'convnext':\n            model = ConvNeXt_model()\n            model.head = nn.Linear(model.head.in_features, num_classes)  # Substituir num_classes pelo número correto de classes\n            num=8\n            \n        elif model_type == 'vit':\n            model = ViT_model()\n            model.heads=nn.Linear(768,2)\n            num=16\n        else:\n            raise ValueError(\"O parâmetro 'model_type' deve ser 'convnext' ou 'vit'.\")\n\n        model = model.to(device)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\n        if model_type == 'convnext':\n            print(\"Experimento 8 - ConvNeXt (Com Fine-Tuning e com RandAugment e AutoAugment)\")\n        elif model_type == 'vit':\n            print(\"Experimento 8 - ViT (Com Fine-Tuning e com RandAugment e AutoAugment)\")\n\n        train_loss, train_accuracy, train_f1, test_loss, test_accuracy,test_f1 = train_model(model_type,8, model, augmented_train_dataloader, test_dataloader,\n                                                                                   criterion, optimizer, scheduler, device, num_epochs, True, num)\n    else:\n        raise ValueError(\"O parâmetro 'scenario' deve ser um número entre 1 e 5.\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:09:24.932909Z","iopub.execute_input":"2023-06-21T21:09:24.933271Z","iopub.status.idle":"2023-06-21T21:09:24.977531Z","shell.execute_reply.started":"2023-06-21T21:09:24.933242Z","shell.execute_reply":"2023-06-21T21:09:24.976460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **3.4. Avaliação de Desempenho**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_experiment_graphs(df, experiment_number):\n    experiment_df = df[df['Experimento'] == experiment_number]\n\n    # Plot epoch x train F1\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Train F1'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Train F1')\n    plt.title(f'Experimento {experiment_number} - Train F1')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x train accuracy\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Train ACC'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Acurácia de Treino')\n    plt.title(f'Experimento {experiment_number} - Acurácia de Treino')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x train loss\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Train Loss'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Perda de Treino')\n    plt.title(f'Experimento {experiment_number} - Perda de Treino')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x test F1\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Test F1'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Test F1')\n    plt.title(f'Experimento {experiment_number} - Test F1')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x test accuracy\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Test ACC'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Acurácia de Teste')\n    plt.title(f'Experimento {experiment_number} - Acurácia de Teste')\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot epoch x test loss\n    plt.figure(figsize=(8, 6))\n    plt.plot(experiment_df['Epoch'], experiment_df['Test Loss'], marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Perda de Teste')\n    plt.title(f'Experimento {experiment_number} - Perda de Teste')\n    plt.tight_layout()\n    plt.show()\n\ndef plot_general_graphs(df):\n    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n\n    # Plot epoch x train F1\n    ax1 = axes[0, 0]\n    for experiment_number in df['Experimento'].unique():\n        experiment_df = df[df['Experimento'] == experiment_number]\n        ax1.plot(experiment_df['Epoch'], experiment_df['Train F1'], marker='o', label=f'Experimento {experiment_number}')\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Train F1')\n    ax1.set_title('Geral - Train F1')\n    ax1.legend()\n\n    # Plot epoch x train loss\n    ax2 = axes[0, 1]\n    for experiment_number in df['Experimento'].unique():\n        experiment_df = df[df['Experimento'] == experiment_number]\n        ax2.plot(experiment_df['Epoch'], experiment_df['Train Loss'], marker='o', label=f'Experimento {experiment_number}')\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Perda de Treino')\n    ax2.set_title('Geral - Perda de Treino')\n    ax2.legend()\n\n    # Plot epoch x test F1\n    ax3 = axes[1, 0]\n    for experiment_number in df['Experimento'].unique():\n        experiment_df = df[df['Experimento'] == experiment_number]\n        ax3.plot(experiment_df['Epoch'], experiment_df['Test F1'], marker='o', label=f'Experimento {experiment_number}')\n    ax3.set_xlabel('Epoch')\n    ax3.set_ylabel('Test F1')\n    ax3.set_title('Geral - Test F1')\n    ax3.legend()\n\n    # Plot epoch x test loss\n    ax4 = axes[1, 1]\n    for experiment_number in df['Experimento'].unique():\n        experiment_df = df[df['Experimento'] == experiment_number]\n        ax4.plot(experiment_df['Epoch'], experiment_df['Test Loss'], marker='o', label=f'Experimento {experiment_number}')\n    ax4.set_xlabel('Epoch')\n    ax4.set_ylabel('Perda de Teste')\n    ax4.set_title('Geral - Perda de Teste')\n    ax4.legend()\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:09:36.210506Z","iopub.execute_input":"2023-06-21T21:09:36.210884Z","iopub.status.idle":"2023-06-21T21:09:36.231700Z","shell.execute_reply.started":"2023-06-21T21:09:36.210854Z","shell.execute_reply":"2023-06-21T21:09:36.230643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nrun_scenario('convnext',1,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T19:35:17.711122Z","iopub.execute_input":"2023-06-21T19:35:17.712834Z","iopub.status.idle":"2023-06-21T19:40:15.693907Z","shell.execute_reply.started":"2023-06-21T19:35:17.712797Z","shell.execute_reply":"2023-06-21T19:40:15.692855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T19:40:15.695628Z","iopub.execute_input":"2023-06-21T19:40:15.696223Z","iopub.status.idle":"2023-06-21T19:40:15.722505Z","shell.execute_reply.started":"2023-06-21T19:40:15.696187Z","shell.execute_reply":"2023-06-21T19:40:15.721417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('convnext',2,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T19:40:15.723876Z","iopub.execute_input":"2023-06-21T19:40:15.724338Z","iopub.status.idle":"2023-06-21T20:20:44.509366Z","shell.execute_reply.started":"2023-06-21T19:40:15.724303Z","shell.execute_reply":"2023-06-21T20:20:44.508403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:20:44.511099Z","iopub.execute_input":"2023-06-21T20:20:44.511701Z","iopub.status.idle":"2023-06-21T20:20:44.531168Z","shell.execute_reply.started":"2023-06-21T20:20:44.511655Z","shell.execute_reply":"2023-06-21T20:20:44.530094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('convnext',3,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T20:20:44.532479Z","iopub.execute_input":"2023-06-21T20:20:44.533348Z","iopub.status.idle":"2023-06-21T21:06:05.114989Z","shell.execute_reply.started":"2023-06-21T20:20:44.533301Z","shell.execute_reply":"2023-06-21T21:06:05.114074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:06:05.116488Z","iopub.execute_input":"2023-06-21T21:06:05.116864Z","iopub.status.idle":"2023-06-21T21:06:05.132136Z","shell.execute_reply.started":"2023-06-21T21:06:05.116828Z","shell.execute_reply":"2023-06-21T21:06:05.131154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('convnext',4,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:09:49.802114Z","iopub.execute_input":"2023-06-21T21:09:49.802694Z","iopub.status.idle":"2023-06-21T21:44:11.821648Z","shell.execute_reply.started":"2023-06-21T21:09:49.802641Z","shell.execute_reply":"2023-06-21T21:44:11.820721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:44:11.823611Z","iopub.execute_input":"2023-06-21T21:44:11.824430Z","iopub.status.idle":"2023-06-21T21:44:11.842370Z","shell.execute_reply.started":"2023-06-21T21:44:11.824395Z","shell.execute_reply":"2023-06-21T21:44:11.841350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('convnext',5,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:44:11.843782Z","iopub.execute_input":"2023-06-21T21:44:11.844210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',1,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',2,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',3,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',4,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_scenario('vit',5,0.1, num_epochs=10, batch_size=16, learning_rate=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_df = df.groupby(['Modelo', 'Experimento']).mean()\nprint(mean_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('metricas.csv', index = False)","metadata":{},"execution_count":null,"outputs":[]}]}